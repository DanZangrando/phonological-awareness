{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "017b8137",
   "metadata": {},
   "source": [
    "# Cuaderno 01: Generaci√≥n de Datasets y Embeddings\n",
    "\n",
    "### Objetivo üéØ\n",
    "Este cuaderno es el punto de partida fundamental de nuestro proyecto. Su objetivo es construir de manera sistem√°tica y robusta todos los **datasets paralelos** (auditivo y visual) y las **representaciones num√©ricas (embeddings)** que servir√°n de base para el entrenamiento de los modelos.\n",
    "\n",
    "### Flujo de Trabajo Consolidado ‚öôÔ∏è\n",
    "\n",
    "1.  **Configuraci√≥n e Instalaci√≥n**: Definiremos los par√°metros globales, incluyendo el **n√∫mero de palabras deseadas** para el experimento y el **modelo `wav2vec2-large`** para asegurar embeddings de dimensi√≥n 1024.\n",
    "2.  **Preprocesamiento - Generaci√≥n de Diccionarios (Robusto)**: Una nueva secci√≥n autom√°tica que:\n",
    "    - Descarga corpus de palabras para espa√±ol e ingl√©s.\n",
    "    - Filtra un gran n√∫mero de palabras candidatas que cumplen nuestros criterios (solo letras v√°lidas).\n",
    "    - **Selecciona aleatoriamente** el n√∫mero deseado de palabras para garantizar la diversidad l√©xica.\n",
    "    - Ordena alfab√©ticamente la lista final y la guarda, creando diccionarios fiables.\n",
    "3.  **Generaci√≥n del Dataset Visual (EMNIST)**: Descarga y extrae im√°genes de letras (`.png`) del dataset EMNIST, con un **l√≠mite de 10 ejemplos por grafema** para mantener el dataset balanceado.\n",
    "4.  **Generaci√≥n de Audio (gTTS)**: Crea archivos `.wav` para cada fonema y para cada palabra de nuestros nuevos y diversos diccionarios.\n",
    "5.  **Extracci√≥n de Embeddings (Wav2Vec2)**: Procesa todos los archivos `.wav` para crear su \"imagen auditiva\", asegurando que se extraiga el **`last_hidden_state`** para obtener los embeddings de dimensi√≥n 1024.\n",
    "6.  **Verificaci√≥n Final**: Se a√±ade un paso final que **verifica en el disco duro** que todos los activos necesarios para las palabras del diccionario se hayan creado con √©xito, garantizando que no habr√° errores de archivos faltantes en los cuadernos posteriores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ac34e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Celda 2: Configuraci√≥n e Instalaci√≥n\n",
    "# ===================================================================\n",
    "%pip install torch transformers gtts pandas numpy scikit-learn nltk unidecode torchvision --quiet\n",
    "\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "from torchvision.datasets import EMNIST\n",
    "from torchvision.transforms import ToPILImage\n",
    "from gtts import gTTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from unidecode import unidecode\n",
    "import shutil\n",
    "import random\n",
    "from PIL import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da0007ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h-lv60-self and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Wav2Vec2 cargado: 'facebook/wav2vec2-large-960h-lv60-self'\n",
      "Dimensi√≥n de embedding confirmada: 1024\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Celda 3: Par√°metros Globales\n",
    "# ===================================================================\n",
    "# --- Par√°metros del Experimento ---\n",
    "# Define con cu√°ntas palabras V√ÅLIDAS Y VERIFICADAS quieres que termine el proceso.\n",
    "NUM_FINAL_WORDS = 500\n",
    "# Buscaremos un n√∫mero mayor de candidatos para tener margen por si falla la generaci√≥n de alg√∫n archivo.\n",
    "NUM_CANDIDATE_WORDS = int(NUM_FINAL_WORDS * 2) \n",
    "MAX_EXAMPLES_PER_GRAPHEME = 10\n",
    "LANGUAGES = ['es', 'en']\n",
    "\n",
    "# Fonemas/Grafemas a generar (25 letras sin '√±' para compatibilidad)\n",
    "PHONEMES = {\n",
    "    'es': sorted(list('abcdefghijklmnopqrstuvwxyz')),\n",
    "    'en': sorted(list('abcdefghijklmnopqrstuvwxyz'))\n",
    "}\n",
    "\n",
    "# --- Rutas del Proyecto ---\n",
    "project_root = Path.cwd().parent\n",
    "raw_data_dir = project_root / \"data/01_raw\"\n",
    "dictionaries_dir = raw_data_dir / \"dictionaries\"\n",
    "output_audio_dir = project_root / \"data/02_processed/audio\"\n",
    "output_embedding_dir = project_root / \"data/02_processed/wav2vec2_embeddings\"\n",
    "output_visual_dir = project_root / \"data/02_processed/visual\"\n",
    "output_word_audio_dir = project_root / \"data/02_processed/word_audio\"\n",
    "output_word_embedding_dir = project_root / \"data/02_processed/word_embeddings\"\n",
    "\n",
    "# --- Creaci√≥n de Directorios ---\n",
    "for path in [dictionaries_dir, output_audio_dir, output_embedding_dir, output_visual_dir, output_word_audio_dir, output_word_embedding_dir]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Configuraci√≥n del Modelo de Embeddings ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Se usa el modelo 'large' para asegurar embeddings de dimensi√≥n 1024\n",
    "MODEL_ID = \"facebook/wav2vec2-large-960h-lv60-self\"\n",
    "processor = Wav2Vec2Processor.from_pretrained(MODEL_ID)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(MODEL_ID).to(DEVICE)\n",
    "EMBED_DIM = model.config.hidden_size\n",
    "print(f\"Modelo Wav2Vec2 cargado: '{MODEL_ID}'\")\n",
    "print(f\"Dimensi√≥n de embedding confirmada: {EMBED_DIM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a1816ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando corpus de NLTK (puede tardar la primera vez)...\n",
      "Corpus descargados.\n",
      "\n",
      "--- Procesando diccionario de candidatos para: ES ---\n",
      "  Corpus original cargado con 25464 palabras.\n",
      "  Se encontraron 19644 palabras v√°lidas despu√©s del filtro.\n",
      "  ‚úÖ √âxito: Se seleccionaron 1000 palabras candidatas.\n",
      "\n",
      "--- Procesando diccionario de candidatos para: EN ---\n",
      "  Corpus original cargado con 235892 palabras.\n",
      "  Se encontraron 234210 palabras v√°lidas despu√©s del filtro.\n",
      "  ‚úÖ √âxito: Se seleccionaron 1000 palabras candidatas.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Celda 4: Preprocesamiento - Generaci√≥n de Lista de PALABRAS CANDIDATAS\n",
    "# ===================================================================\n",
    "def generate_candidate_lists(num_candidates, languages):\n",
    "    print(\"Descargando corpus de NLTK (puede tardar la primera vez)...\")\n",
    "    nltk.download('words', quiet=True); nltk.download('cess_esp', quiet=True)\n",
    "    print(\"Corpus descargados.\")\n",
    "    valid_chars = set('abcdefghijklmnopqrstuvwxyz')\n",
    "    word_sources = {'en': set(nltk.corpus.words.words()), 'es': set(nltk.corpus.cess_esp.words())}\n",
    "    candidate_words = {}\n",
    "    \n",
    "    for lang in languages:\n",
    "        print(f\"\\n--- Procesando diccionario de candidatos para: {lang.upper()} ---\")\n",
    "        source_words = word_sources.get(lang, set())\n",
    "        print(f\"  Corpus original cargado con {len(source_words)} palabras.\")\n",
    "        valid_words = {unidecode(w.lower()) for w in source_words if len(unidecode(w.lower())) > 2 and set(unidecode(w.lower())).issubset(valid_chars)}\n",
    "        print(f\"  Se encontraron {len(valid_words)} palabras v√°lidas despu√©s del filtro.\")\n",
    "        if len(valid_words) >= num_candidates:\n",
    "            # Seleccionar aleatoriamente para asegurar la variedad.\n",
    "            candidate_words[lang] = random.sample(sorted(list(valid_words)), num_candidates)\n",
    "            print(f\"  ‚úÖ √âxito: Se seleccionaron {len(candidate_words[lang])} palabras candidatas.\")\n",
    "        else:\n",
    "            print(f\"  ‚ùå ADVERTENCIA: No se encontraron suficientes palabras candidatas (Se necesitan {num_candidates}).\")\n",
    "            candidate_words[lang] = []\n",
    "    return candidate_words\n",
    "\n",
    "CANDIDATE_WORDS = generate_candidate_lists(NUM_CANDIDATE_WORDS, LANGUAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae4b44c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generando Dataset Visual (EMNIST) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b155e18531614740afdc16621d3d441d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Procesando im√°genes de EMNIST:   0%|          | 0/124800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset Visual EMNIST generado con √©xito.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Celda 5: Generaci√≥n del Dataset Visual (EMNIST)\n",
    "# ===================================================================\n",
    "def generate_visual_dataset(output_dir, raw_dir, max_examples=10):\n",
    "    print(\"\\n--- Generando Dataset Visual (EMNIST) ---\")\n",
    "    emnist_dataset = EMNIST(root=raw_dir, split='letters', download=True, train=True)\n",
    "    label_map = {i: chr(ord('a') + i - 1) for i in range(1, 27)}\n",
    "    if output_dir.exists(): shutil.rmtree(output_dir)\n",
    "    output_dir.mkdir(parents=True)\n",
    "    counts = {chr(ord('a') + i): 0 for i in range(26)}\n",
    "    for image, label_idx in tqdm(emnist_dataset, desc=\"Procesando im√°genes de EMNIST\"):\n",
    "        label_char = label_map.get(label_idx)\n",
    "        if label_char and counts[label_char] < max_examples:\n",
    "            char_dir = output_dir / label_char\n",
    "            char_dir.mkdir(exist_ok=True)\n",
    "            pil_image = image.rotate(-90, expand=True).transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            counts[label_char] += 1\n",
    "            image_path = char_dir / f\"{label_char}_{counts[label_char]}.png\"\n",
    "            pil_image.save(image_path)\n",
    "    print(\"‚úÖ Dataset Visual EMNIST generado con √©xito.\")\n",
    "\n",
    "generate_visual_dataset(output_visual_dir, raw_data_dir, max_examples=MAX_EXAMPLES_PER_GRAPHEME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c61f24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4446eb0b11654abf9af6e7c18f860a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generando audio para 'es' en 'es':   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb6f338d490547f5b13920d6a91431b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generando audio para 'es' en 'es':   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se pudo generar audio para 'acumulacion': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'contemplaban': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'dimension': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'arrojados': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'establecimiento': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'conmover': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'vigor': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'intocables': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'relata': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'bell': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'sueldos': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'cientificos': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'pensandolo': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'supere': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'destituidos': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'descoyuntada': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'siete': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'obstaculo': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'editoras': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'cardan': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'legionella': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'trajes': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'nebulosas': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'jacarandas': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'quedamos': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'logico': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'directores': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'relojes': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'almacenaba': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'lindando': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'infierno': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'debates': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'comprometeran': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'musicos': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'apelusada': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'liderara': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'minuto': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'gloriosa': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'desordenadamente': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'drop': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'indicado': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'eurocopa': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'pirineo': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'leucemias': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'telefonicas': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'segunda': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'manuscritos': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'limpieza': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'prioritario': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'nodrizas': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'significacion': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'parezcan': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'presunto': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'reverdecida': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'chen': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'tomar': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'carece': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'librerias': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'privado': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'reticencias': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'rotura': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'entrenar': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'persistente': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'electoral': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'superarlo': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'efectua': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'desairado': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'ganancia': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'advierten': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'canarios': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'hambre': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'decreto': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'liquidarle': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'calma': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'insistentes': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'gobernar': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'inmobiliarios': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'transcendente': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'terrorismo': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'transmitio': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'reprise': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'inter': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'favoritas': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'buho': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'seca': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'artilleros': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'juventud': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'sabiduria': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'submarinos': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'inmigrante': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'obreros': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'subdialecto': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'abrupto': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'antiterrorista': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'culpable': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'utilizarlos': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'dedos': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'botin': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'matricula': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'hispanoamericanos': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'basura': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'mercados': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'rayo': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'dias': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'otorgados': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'cortar': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'pri': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'chaval': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'examen': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'decorativo': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'relegado': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'cristal': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'sobra': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'entiendo': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'casquivano': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'ramos': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'impediria': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'objeciones': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m generate_audio(PHONEMES[lang], output_audio_dir / lang, lang)\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m CANDIDATE_WORDS[lang]:\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[43mgenerate_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCANDIDATE_WORDS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_word_audio_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mgenerate_audio\u001b[39m\u001b[34m(text_list, output_dir, lang)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m tqdm(text_list, desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGenerando audio para \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlang\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m en \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m      7\u001b[39m     file_path = output_dir / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.wav\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_path.exists():\n\u001b[32m     10\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Celda 6: Generaci√≥n de Audio para Fonemas y Palabras\n",
    "# ===================================================================\n",
    "def generate_audio(text_list, output_dir, lang):\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for text in tqdm(text_list, desc=f\"Generando audio para '{lang}' en '{output_dir.name}'\"):\n",
    "        file_path = output_dir / f\"{text}.wav\"\n",
    "        time.sleep(5)\n",
    "        if not file_path.exists():\n",
    "            try:\n",
    "                gTTS(text, lang=lang).save(str(file_path))\n",
    "            except Exception as e:\n",
    "                print(f\"No se pudo generar audio para '{text}': {e}\")\n",
    "\n",
    "for lang in LANGUAGES:\n",
    "    generate_audio(PHONEMES[lang], output_audio_dir / lang, lang)\n",
    "    if CANDIDATE_WORDS[lang]:\n",
    "        generate_audio(CANDIDATE_WORDS[lang], output_word_audio_dir / lang, lang)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395eaef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943a47d967ff43419bdab1b19f0961dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extrayendo embeddings de 'es':   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1855f7f4b0403dad587603fb240efe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extrayendo embeddings de 'es':   0%|          | 0/788 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5df8d06cb974e0a82eaadc5952e6e83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extrayendo embeddings de 'en':   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f4c7374d6f4345b6f3d202a5b6f094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extrayendo embeddings de 'en':   0%|          | 0/799 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Celda 7: Extracci√≥n de Embeddings Auditivos (Wav2Vec2)\n",
    "# ===================================================================\n",
    "import librosa\n",
    "def extract_embeddings(audio_dir, embedding_dir):\n",
    "    embedding_dir.mkdir(parents=True, exist_ok=True)\n",
    "    audio_files = list(audio_dir.glob(\"*.wav\"))\n",
    "    for audio_path in tqdm(audio_files, desc=f\"Extrayendo embeddings de '{audio_dir.name}'\"):\n",
    "        text = audio_path.stem\n",
    "        embedding_path = embedding_dir / f\"{text}.npy\"\n",
    "        if not embedding_path.exists():\n",
    "            try:\n",
    "                speech_array, sr = librosa.load(str(audio_path), sr=16000)\n",
    "                inputs = processor(speech_array, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "                with torch.no_grad():\n",
    "                    outputs = model.wav2vec2(inputs.input_values.to(DEVICE))\n",
    "                    hidden_states = outputs.last_hidden_state\n",
    "                np.save(embedding_path, hidden_states.cpu().numpy().squeeze())\n",
    "            except Exception as e:\n",
    "                print(f\"No se pudo extraer embedding para '{text}': {e}\")\n",
    "\n",
    "for lang in LANGUAGES:\n",
    "    extract_embeddings(output_audio_dir / lang, output_embedding_dir / lang)\n",
    "    if CANDIDATE_WORDS[lang]:\n",
    "        extract_embeddings(output_word_audio_dir / lang, output_word_embedding_dir / lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60966f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Creaci√≥n de Diccionarios a partir de Embeddings Verificados ---\n",
      "\n",
      "--- Procesando idioma: ES ---\n",
      "Encontrados 1169 embeddings de palabras. Verificando fonemas correspondientes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25868401e850456fbc2cc0074e113bb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Verificando activos (es):   0%|          | 0/1169 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ‚úÖ √âxito: Se gener√≥ el diccionario 'es_words.txt' con un total de 1169 palabras verificadas.\n",
      "\n",
      "--- Procesando idioma: EN ---\n",
      "Encontrados 1197 embeddings de palabras. Verificando fonemas correspondientes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c725ad94fab444a3a059cd3031de4dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Verificando activos (en):   0%|          | 0/1197 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ‚úÖ √âxito: Se gener√≥ el diccionario 'en_words.txt' con un total de 1197 palabras verificadas.\n",
      "\n",
      "\n",
      "‚úÖ Proceso de creaci√≥n de diccionarios finalizado.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Celda 8: Creaci√≥n de Diccionarios Basada en Embeddings Existentes (Corregida)\n",
    "# ===================================================================\n",
    "from pathlib import Path # Importar Path para manejar las rutas\n",
    "\n",
    "print(\"\\n--- Creaci√≥n de Diccionarios a partir de Embeddings Verificados ---\")\n",
    "\n",
    "# --- ¬°NUEVO! Definici√≥n de rutas directas ---\n",
    "# Asumimos que el notebook se ejecuta desde una carpeta como 'notebooks/03_auditory_pathway.ipynb'\n",
    "# y los datos est√°n en 'data/', por lo que subimos un nivel.\n",
    "project_root = Path.cwd().parent \n",
    "phoneme_embedding_dir_base = project_root / \"data/02_processed/wav2vec2_embeddings\"\n",
    "word_embedding_dir_base = project_root / \"data/02_processed/word_embeddings\"\n",
    "\n",
    "for lang in LANGUAGES:\n",
    "    print(f\"\\n--- Procesando idioma: {lang.upper()} ---\")\n",
    "    \n",
    "    # Directorios espec√≠ficos para el idioma actual\n",
    "    phoneme_dir = phoneme_embedding_dir_base / lang\n",
    "    word_dir = word_embedding_dir_base / lang\n",
    "    \n",
    "    # Verificar si los directorios existen para evitar errores\n",
    "    if not word_dir.exists() or not phoneme_dir.exists():\n",
    "        print(f\" ‚ùå ERROR: No se encontraron los directorios de embeddings para '{lang}'.\")\n",
    "        print(f\"   - Buscando en: {word_dir}\")\n",
    "        print(f\"   - Buscando en: {phoneme_dir}\")\n",
    "        print(\"   Saltando este idioma...\")\n",
    "        continue\n",
    "\n",
    "    # 1. Obtener todas las palabras candidatas directamente de los archivos .npy existentes.\n",
    "    word_candidates = [p.stem for p in word_dir.glob(\"*.npy\")]\n",
    "    \n",
    "    verified_words = []\n",
    "    \n",
    "    # 2. Filtrar la lista: verificar que para cada palabra, todos sus fonemas (letras) tambi√©n existen.\n",
    "    print(f\"Encontrados {len(word_candidates)} embeddings de palabras. Verificando fonemas correspondientes...\")\n",
    "    for word in tqdm(word_candidates, desc=f\"Verificando activos ({lang})\"):\n",
    "        all_phonemes_exist = all((phoneme_dir / f\"{phoneme}.npy\").exists() for phoneme in word)\n",
    "        \n",
    "        if all_phonemes_exist:\n",
    "            verified_words.append(word)\n",
    "\n",
    "    # 3. Generar el diccionario con TODAS las palabras que pasaron el filtro.\n",
    "    if verified_words:\n",
    "        final_list = sorted(verified_words)\n",
    "        \n",
    "        # Asegurarse de que el directorio de diccionarios exista\n",
    "        dictionaries_dir.mkdir(parents=True, exist_ok=True)\n",
    "        dict_path = dictionaries_dir / f\"{lang}_words.txt\"\n",
    "        \n",
    "        with open(dict_path, 'w', encoding='utf-8') as f:\n",
    "            for word in final_list:\n",
    "                f.write(f\"{word}\\n\")\n",
    "                \n",
    "        # 4. Informar el resultado final con el recuento total.\n",
    "        print(f\" ‚úÖ √âxito: Se gener√≥ el diccionario '{dict_path.name}' con un total de {len(final_list)} palabras verificadas.\")\n",
    "    else:\n",
    "        print(f\" ‚ö†Ô∏è Advertencia: No se encontr√≥ ninguna palabra que cumpliera con los requisitos para '{lang}'. No se gener√≥ el diccionario.\")\n",
    "\n",
    "print(\"\\n\\n‚úÖ Proceso de creaci√≥n de diccionarios finalizado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
