{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "017b8137",
   "metadata": {},
   "source": [
    "# Cuaderno 01: Generación de Datasets Auditivos y Visuales\n",
    "\n",
    "**Objetivo:** Crear los datasets paralelos que servirán de base para todo el proyecto:\n",
    "1.  **Dataset Auditivo**: Generar archivos de audio `.wav` para una lista de fonemas/letras clave.\n",
    "2.  **Dataset Visual**: Descargar y extraer imágenes de letras (`.png`) del dataset **EMNIST** que correspondan a los grafemas de nuestras listas.\n",
    "\n",
    "**Flujo de Trabajo:**\n",
    "1.  **Instalación de Librerías**: Instalar `gTTS`, `pydub` y `torchvision`.\n",
    "2.  **Configuración**: Definir las listas de fonemas/grafemas y las rutas de salida para ambos datasets.\n",
    "3.  **Parte A**: Generar los archivos de audio.\n",
    "4.  **Parte B**: Descargar, filtrar y guardar las imágenes de letras correspondientes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35353702",
   "metadata": {},
   "source": [
    "## Paso 1: Instalación de Librerías\n",
    "\n",
    "Instalamos las librerías necesarias:\n",
    "* `gTTS` y `pydub`: Para la síntesis de voz y manejo de audio.\n",
    "* `torch` y `torchvision`: Para descargar y manipular el dataset de imágenes EMNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5ba352",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gTTS pydub torch torchvision matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd86ca3",
   "metadata": {},
   "source": [
    "## Paso 2: Configuración General\n",
    "\n",
    "Importamos librerías y definimos las listas de fonemas/grafemas y las rutas de salida. Ahora incluimos rutas para los datos visuales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a1816ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se guardará un máximo de 50 imágenes por grafema.\n",
      "Fonemas a procesar para español: 27\n",
      "Fonemas a procesar para inglés: 33\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import EMNIST\n",
    "from PIL import Image\n",
    "\n",
    "# --- Rutas de Salida ---\n",
    "project_root = Path.cwd().parent\n",
    "\n",
    "# Rutas para el dataset auditivo\n",
    "output_dir_audio_es = project_root / \"data/02_processed/phoneme_audio/es\"\n",
    "output_dir_audio_en = project_root / \"data/02_processed/phoneme_audio/en\"\n",
    "output_dir_audio_es.mkdir(parents=True, exist_ok=True)\n",
    "output_dir_audio_en.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Rutas para el dataset visual\n",
    "output_dir_emnist_root = project_root / \"data/01_raw/emnist\"\n",
    "output_dir_visual_es = project_root / \"data/02_processed/grapheme_images/es\"\n",
    "output_dir_visual_en = project_root / \"data/02_processed/grapheme_images/en\"\n",
    "output_dir_visual_es.mkdir(parents=True, exist_ok=True)\n",
    "output_dir_visual_en.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Listas de Fonemas/Grafemas ---\n",
    "phonemes_es = [\n",
    "    'a', 'e', 'i', 'o', 'u', 'b', \"c\", 'd', 'f', 'g', 'j',\"h\", 'k', 'l', 'm', 'n', 'ñ', 'p', 'r', 'rr', 's', 't', 'y',\"v\", 'z', 'ch', 'll'\n",
    "]\n",
    "phonemes_en = [\n",
    "    'a', 'e', 'i', 'o', 'u', 'ay', 'ee', 'igh', 'oh', 'oo', 'b',\"c\", 'd', 'f', 'g', 'h', 'j', 'k', 'l', 'm', 'n', 'p', 'r', 's', 't', 'v', 'w', 'y', 'z', 'ch', 'sh', 'th', 'ng'\n",
    "]\n",
    "\n",
    "# --- Parámetros de Procesamiento ---\n",
    "MAX_IMAGES_PER_LETTER = 50\n",
    "\n",
    "print(f\"Se guardará un máximo de {MAX_IMAGES_PER_LETTER} imágenes por grafema.\")\n",
    "print(f\"Fonemas a procesar para español: {len(phonemes_es)}\")\n",
    "print(f\"Fonemas a procesar para inglés: {len(phonemes_en)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628a5678",
   "metadata": {},
   "source": [
    "## Parte A: Generación del Dataset Auditivo\n",
    "\n",
    "Esta sección genera los archivos `.wav` para cada fonema/letra de nuestras listas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6980ddb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iniciando generación de audio para: ES ---\n",
      "(1/27) Audio para 'a' guardado.\n",
      "(2/27) Audio para 'e' guardado.\n",
      "(3/27) Audio para 'i' guardado.\n",
      "(4/27) Audio para 'o' guardado.\n",
      "(5/27) Audio para 'u' guardado.\n",
      "(6/27) Audio para 'b' guardado.\n",
      "(7/27) Audio para 'c' guardado.\n",
      "(8/27) Audio para 'd' guardado.\n",
      "(9/27) Audio para 'f' guardado.\n",
      "(10/27) Audio para 'g' guardado.\n",
      "(11/27) Audio para 'j' guardado.\n",
      "(12/27) Audio para 'h' guardado.\n",
      "(13/27) Audio para 'k' guardado.\n",
      "(14/27) Audio para 'l' guardado.\n",
      "(15/27) Audio para 'm' guardado.\n",
      "(16/27) Audio para 'n' guardado.\n",
      "(17/27) Audio para 'ñ' guardado.\n",
      "(18/27) Audio para 'p' guardado.\n",
      "(19/27) Audio para 'r' guardado.\n",
      "(20/27) Audio para 'rr' guardado.\n",
      "(21/27) Audio para 's' guardado.\n",
      "(22/27) Audio para 't' guardado.\n",
      "(23/27) Audio para 'y' guardado.\n",
      "(24/27) Audio para 'v' guardado.\n",
      "(25/27) Audio para 'z' guardado.\n",
      "(26/27) Audio para 'ch' guardado.\n",
      "(27/27) Audio para 'll' guardado.\n",
      "\n",
      "--- Iniciando generación de audio para: EN ---\n",
      "(1/33) Audio para 'a' guardado.\n",
      "(2/33) Audio para 'e' guardado.\n",
      "(3/33) Audio para 'i' guardado.\n",
      "(4/33) Audio para 'o' guardado.\n",
      "(5/33) Audio para 'u' guardado.\n",
      "(6/33) Audio para 'ay' guardado.\n",
      "(7/33) Audio para 'ee' guardado.\n",
      "(8/33) Audio para 'igh' guardado.\n",
      "(9/33) Audio para 'oh' guardado.\n",
      "(10/33) Audio para 'oo' guardado.\n",
      "(11/33) Audio para 'b' guardado.\n",
      "(12/33) Audio para 'c' guardado.\n",
      "(13/33) Audio para 'd' guardado.\n",
      "(14/33) Audio para 'f' guardado.\n",
      "(15/33) Audio para 'g' guardado.\n",
      "(16/33) Audio para 'h' guardado.\n",
      "(17/33) Audio para 'j' guardado.\n",
      "(18/33) Audio para 'k' guardado.\n",
      "(19/33) Audio para 'l' guardado.\n",
      "(20/33) Audio para 'm' guardado.\n",
      "(21/33) Audio para 'n' guardado.\n",
      "(22/33) Audio para 'p' guardado.\n",
      "(23/33) Audio para 'r' guardado.\n",
      "(24/33) Audio para 's' guardado.\n",
      "(25/33) Audio para 't' guardado.\n",
      "(26/33) Audio para 'v' guardado.\n",
      "(27/33) Audio para 'w' guardado.\n",
      "(28/33) Audio para 'y' guardado.\n",
      "(29/33) Audio para 'z' guardado.\n",
      "(30/33) Audio para 'ch' guardado.\n",
      "(31/33) Audio para 'sh' guardado.\n",
      "(32/33) Audio para 'th' guardado.\n",
      "(33/33) Audio para 'ng' guardado.\n",
      "\n",
      "--- Proceso de generación de audio completado. ---\n"
     ]
    }
   ],
   "source": [
    "def generate_audio_files(phoneme_list, lang_code, output_path):\n",
    "    print(f\"\\n--- Iniciando generación de audio para: {lang_code.upper()} ---\")\n",
    "    for i, phoneme in enumerate(phoneme_list):\n",
    "        wav_filepath = output_path / f\"{phoneme}.wav\"\n",
    "        if wav_filepath.exists():\n",
    "            print(f\"({i+1}/{len(phoneme_list)}) Audio para '{phoneme}' ya existe. Omitiendo.\")\n",
    "            continue\n",
    "        try:\n",
    "            tts = gTTS(text=phoneme, lang=lang_code, slow=True)\n",
    "            mp3_temp_path = output_path / \"temp.mp3\"\n",
    "            tts.save(mp3_temp_path)\n",
    "            audio = AudioSegment.from_mp3(mp3_temp_path)\n",
    "            audio.export(wav_filepath, format=\"wav\", parameters=[\"-ac\", \"1\", \"-ar\", \"16000\"])\n",
    "            os.remove(mp3_temp_path)\n",
    "            print(f\"({i+1}/{len(phoneme_list)}) Audio para '{phoneme}' guardado.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando '{phoneme}': {e}\")\n",
    "            if os.path.exists(mp3_temp_path): os.remove(mp3_temp_path)\n",
    "\n",
    "# Generar audios para ambos idiomas\n",
    "generate_audio_files(phonemes_es, 'es', output_dir_audio_es)\n",
    "generate_audio_files(phonemes_en, 'en', output_dir_audio_en)\n",
    "print(\"\\n--- Proceso de generación de audio completado. ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d893173",
   "metadata": {},
   "source": [
    "## Parte B: Generación del Dataset Visual\n",
    "\n",
    "Ahora, descargamos el dataset EMNIST y extraemos las imágenes de las letras que corresponden a nuestros grafemas de una sola letra (ej. 'a', 'b', 'c'). Las imágenes se guardarán en subcarpetas por cada letra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06d93d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Descargando y preparando EMNIST ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562M/562M [28:48<00:00, 325kB/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Extrayendo un máximo de 50 imágenes para 24 grafemas ---\n",
      "(1/24) Límite de imágenes para 'a' ya alcanzado. Omitiendo.\n",
      "(2/24) Límite de imágenes para 'e' ya alcanzado. Omitiendo.\n",
      "(3/24) Límite de imágenes para 'i' ya alcanzado. Omitiendo.\n",
      "(4/24) Límite de imágenes para 'o' ya alcanzado. Omitiendo.\n",
      "(5/24) Límite de imágenes para 'u' ya alcanzado. Omitiendo.\n",
      "(6/24) Límite de imágenes para 'b' ya alcanzado. Omitiendo.\n",
      "(7/24) Límite de imágenes para 'c' ya alcanzado. Omitiendo.\n",
      "(8/24) Límite de imágenes para 'd' ya alcanzado. Omitiendo.\n",
      "(9/24) Límite de imágenes para 'f' ya alcanzado. Omitiendo.\n",
      "(10/24) Límite de imágenes para 'g' ya alcanzado. Omitiendo.\n",
      "(11/24) Límite de imágenes para 'j' ya alcanzado. Omitiendo.\n",
      "(12/24) Límite de imágenes para 'h' ya alcanzado. Omitiendo.\n",
      "(13/24) Límite de imágenes para 'k' ya alcanzado. Omitiendo.\n",
      "(14/24) Límite de imágenes para 'l' ya alcanzado. Omitiendo.\n",
      "(15/24) Límite de imágenes para 'm' ya alcanzado. Omitiendo.\n",
      "(16/24) Límite de imágenes para 'n' ya alcanzado. Omitiendo.\n",
      "Grafema 'ñ' no encontrado en EMNIST 'letters'.\n",
      "(18/24) Límite de imágenes para 'p' ya alcanzado. Omitiendo.\n",
      "(19/24) Límite de imágenes para 'r' ya alcanzado. Omitiendo.\n",
      "(20/24) Límite de imágenes para 's' ya alcanzado. Omitiendo.\n",
      "(21/24) Límite de imágenes para 't' ya alcanzado. Omitiendo.\n",
      "(22/24) Límite de imágenes para 'y' ya alcanzado. Omitiendo.\n",
      "(23/24) Límite de imágenes para 'v' ya alcanzado. Omitiendo.\n",
      "(24/24) Límite de imágenes para 'z' ya alcanzado. Omitiendo.\n",
      "\n",
      "--- Extrayendo un máximo de 50 imágenes para 24 grafemas ---\n",
      "(1/24) Límite de imágenes para 'a' ya alcanzado. Omitiendo.\n",
      "(2/24) Límite de imágenes para 'e' ya alcanzado. Omitiendo.\n",
      "(3/24) Límite de imágenes para 'i' ya alcanzado. Omitiendo.\n",
      "(4/24) Límite de imágenes para 'o' ya alcanzado. Omitiendo.\n",
      "(5/24) Límite de imágenes para 'u' ya alcanzado. Omitiendo.\n",
      "(6/24) Límite de imágenes para 'b' ya alcanzado. Omitiendo.\n",
      "(7/24) Límite de imágenes para 'c' ya alcanzado. Omitiendo.\n",
      "(8/24) Límite de imágenes para 'd' ya alcanzado. Omitiendo.\n",
      "(9/24) Límite de imágenes para 'f' ya alcanzado. Omitiendo.\n",
      "(10/24) Límite de imágenes para 'g' ya alcanzado. Omitiendo.\n",
      "(11/24) Límite de imágenes para 'h' ya alcanzado. Omitiendo.\n",
      "(12/24) Límite de imágenes para 'j' ya alcanzado. Omitiendo.\n",
      "(13/24) Límite de imágenes para 'k' ya alcanzado. Omitiendo.\n",
      "(14/24) Límite de imágenes para 'l' ya alcanzado. Omitiendo.\n",
      "(15/24) Límite de imágenes para 'm' ya alcanzado. Omitiendo.\n",
      "(16/24) Límite de imágenes para 'n' ya alcanzado. Omitiendo.\n",
      "(17/24) Límite de imágenes para 'p' ya alcanzado. Omitiendo.\n",
      "(18/24) Límite de imágenes para 'r' ya alcanzado. Omitiendo.\n",
      "(19/24) Límite de imágenes para 's' ya alcanzado. Omitiendo.\n",
      "(20/24) Límite de imágenes para 't' ya alcanzado. Omitiendo.\n",
      "(21/24) Límite de imágenes para 'v' ya alcanzado. Omitiendo.\n",
      "(22/24) Límite de imágenes para 'w' ya alcanzado. Omitiendo.\n",
      "(23/24) Límite de imágenes para 'y' ya alcanzado. Omitiendo.\n",
      "(24/24) Límite de imágenes para 'z' ya alcanzado. Omitiendo.\n",
      "\n",
      "--- Proceso de generación de imágenes completado. ---\n"
     ]
    }
   ],
   "source": [
    "def generate_visual_dataset(phoneme_list, emnist_dataset, output_path, max_images):\n",
    "    \"\"\"\n",
    "    Filtra EMNIST y guarda un número máximo de imágenes por grafema.\n",
    "    \"\"\"\n",
    "    class_to_char = {i: c for i, c in enumerate(emnist_dataset.classes) if c.isalpha()}\n",
    "    char_to_class = {c: i for i, c in class_to_char.items()}\n",
    "    \n",
    "    single_char_graphemes = [p for p in phoneme_list if len(p) == 1 and p.isalpha()]\n",
    "    \n",
    "    print(f\"\\n--- Extrayendo un máximo de {max_images} imágenes para {len(single_char_graphemes)} grafemas ---\")\n",
    "    \n",
    "    images_by_label = {label: [] for label in range(len(emnist_dataset.classes))}\n",
    "    for image, label in emnist_dataset:\n",
    "        images_by_label[label].append(image)\n",
    "\n",
    "    for i, grapheme in enumerate(single_char_graphemes):\n",
    "        grapheme_lower = grapheme.lower()\n",
    "        if grapheme_lower in char_to_class:\n",
    "            class_idx = char_to_class[grapheme_lower]\n",
    "            grapheme_dir = output_path / grapheme_lower\n",
    "            grapheme_dir.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            num_existing = len(list(grapheme_dir.glob(\"*.png\")))\n",
    "            if num_existing >= max_images:\n",
    "                print(f\"({i+1}/{len(single_char_graphemes)}) Límite de imágenes para '{grapheme_lower}' ya alcanzado. Omitiendo.\")\n",
    "                continue\n",
    "\n",
    "            images_saved_count = 0\n",
    "            for img_obj in images_by_label[class_idx]:\n",
    "                if images_saved_count >= max_images:\n",
    "                    break\n",
    "                \n",
    "                img = img_obj.transpose(Image.Transpose.ROTATE_270)\n",
    "                img = img.transpose(Image.Transpose.FLIP_LEFT_RIGHT)\n",
    "                # Usamos el contador actual para el nombre del archivo\n",
    "                img.save(grapheme_dir / f\"{grapheme_lower}_{num_existing + images_saved_count}.png\")\n",
    "                images_saved_count += 1\n",
    "            \n",
    "            print(f\"({i+1}/{len(single_char_graphemes)}) Se guardaron {images_saved_count} imágenes para '{grapheme_lower}'.\")\n",
    "        else:\n",
    "            print(f\"Grafema '{grapheme_lower}' no encontrado en EMNIST 'letters'.\")\n",
    "\n",
    "# --- Descargar el dataset EMNIST una sola vez ---\n",
    "print(\"\\n--- Descargando y preparando EMNIST ---\")\n",
    "emnist_data = EMNIST(root=output_dir_emnist_root, split='letters', download=True)\n",
    "            \n",
    "# --- CORRECCIÓN: Llamadas a la función actualizadas ---\n",
    "# Añadimos el argumento 'max_images' que ahora es requerido\n",
    "generate_visual_dataset(phonemes_es, emnist_data, output_dir_visual_es, max_images=MAX_IMAGES_PER_LETTER)\n",
    "generate_visual_dataset(phonemes_en, emnist_data, output_dir_visual_en, max_images=MAX_IMAGES_PER_LETTER)\n",
    "\n",
    "print(\"\\n--- Proceso de generación de imágenes completado. ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
