{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "017b8137",
   "metadata": {},
   "source": [
    "# Cuaderno 02: Entrenamiento de Clasificadores Expertos (Versi√≥n Refactorizada)\n",
    "\n",
    "### Objetivo üéØ\n",
    "Este cuaderno entrena y valida de manera sistem√°tica nuestros dos **clasificadores expertos**. El c√≥digo ha sido refactorizado para mejorar la claridad, eliminar la redundancia y generar un conjunto completo de artefactos de evaluaci√≥n para cada modelo.\n",
    "\n",
    "### Cambios Clave en esta Versi√≥n ‚ú®\n",
    "\n",
    "1.  **C√≥digo Simplificado**: El entrenamiento, la evaluaci√≥n y la visualizaci√≥n se han encapsulado en funciones reutilizables, haciendo el flujo de trabajo m√°s limpio y f√°cil de entender.\n",
    "2.  **Visualizaciones Mejoradas**:\n",
    "    -   **Para Fonemas**: Generamos un an√°lisis completo que incluye **curvas de aprendizaje**, un **gr√°fico t-SNE** para visualizar la separabilidad de los fonemas, la **matriz de confusi√≥n** y el **heatmap de logits**.\n",
    "    -   **Para Palabras**: Dado el alto n√∫mero de clases, reemplazamos la costosa matriz de confusi√≥n por visualizaciones m√°s informativas a gran escala: las **curvas de aprendizaje** para monitorear el entrenamiento y un **gr√°fico t-SNE** para evaluar la clusterizaci√≥n de las palabras en el espacio de embeddings.\n",
    "3.  **Guardado Sistem√°tico de Artefactos**: Todas las figuras generadas (`.png`) y los reportes de clasificaci√≥n (`.csv`) se guardan autom√°ticamente en los directorios `results/figures` y `results/tables`, respectivamente.\n",
    "\n",
    "Al final de este cuaderno, tendremos cuatro modelos expertos robustos y un conjunto completo de resultados para documentar su rendimiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ac34e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Celda 2: Configuraci√≥n e Instalaci√≥n\n",
    "# ===================================================================\n",
    "%pip install torch scikit-learn seaborn pandas matplotlib --quiet\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import glob\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "# Suprimir advertencias de sklearn para mayor claridad en la salida\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='sklearn')\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0007ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h-lv60-self and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Wav2Vec2 cargado: 'facebook/wav2vec2-large-960h-lv60-self'\n",
      "Dimensi√≥n de embedding confirmada: 1024\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Celda 3: Par√°metros Globales\n",
    "# ===================================================================\n",
    "# --- Par√°metros del Experimento ---\n",
    "# Define con cu√°ntas palabras V√ÅLIDAS Y VERIFICADAS quieres que termine el proceso.\n",
    "NUM_FINAL_WORDS = 100\n",
    "# Buscaremos un n√∫mero mayor de candidatos para tener margen por si falla la generaci√≥n de alg√∫n archivo.\n",
    "NUM_CANDIDATE_WORDS = int(NUM_FINAL_WORDS * 2) \n",
    "MAX_EXAMPLES_PER_GRAPHEME = 10\n",
    "LANGUAGES = ['es', 'en']\n",
    "\n",
    "# Fonemas/Grafemas a generar (25 letras sin '√±' para compatibilidad)\n",
    "PHONEMES = {\n",
    "    'es': sorted(list('abcdefghijklmnopqrstuvwxyz')),\n",
    "    'en': sorted(list('abcdefghijklmnopqrstuvwxyz'))\n",
    "}\n",
    "\n",
    "# --- Rutas del Proyecto ---\n",
    "project_root = Path.cwd().parent\n",
    "raw_data_dir = project_root / \"data/01_raw\"\n",
    "dictionaries_dir = raw_data_dir / \"dictionaries\"\n",
    "output_audio_dir = project_root / \"data/02_processed/audio\"\n",
    "output_embedding_dir = project_root / \"data/02_processed/wav2vec2_embeddings\"\n",
    "output_visual_dir = project_root / \"data/02_processed/visual\"\n",
    "output_word_audio_dir = project_root / \"data/02_processed/word_audio\"\n",
    "output_word_embedding_dir = project_root / \"data/02_processed/word_embeddings\"\n",
    "\n",
    "# --- Creaci√≥n de Directorios ---\n",
    "for path in [dictionaries_dir, output_audio_dir, output_embedding_dir, output_visual_dir, output_word_audio_dir, output_word_embedding_dir]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Configuraci√≥n del Modelo de Embeddings ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Se usa el modelo 'large' para asegurar embeddings de dimensi√≥n 1024\n",
    "MODEL_ID = \"facebook/wav2vec2-large-960h-lv60-self\"\n",
    "processor = Wav2Vec2Processor.from_pretrained(MODEL_ID)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(MODEL_ID).to(DEVICE)\n",
    "EMBED_DIM = model.config.hidden_size\n",
    "print(f\"Modelo Wav2Vec2 cargado: '{MODEL_ID}'\")\n",
    "print(f\"Dimensi√≥n de embedding confirmada: {EMBED_DIM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a1816ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando corpus de NLTK (puede tardar la primera vez)...\n",
      "Corpus descargados.\n",
      "\n",
      "--- Procesando diccionario de candidatos para: ES ---\n",
      "  Corpus original cargado con 25464 palabras.\n",
      "  Se encontraron 19644 palabras v√°lidas despu√©s del filtro.\n",
      "  ‚úÖ √âxito: Se seleccionaron 200 palabras candidatas.\n",
      "\n",
      "--- Procesando diccionario de candidatos para: EN ---\n",
      "  Corpus original cargado con 235892 palabras.\n",
      "  Se encontraron 234210 palabras v√°lidas despu√©s del filtro.\n",
      "  ‚úÖ √âxito: Se seleccionaron 200 palabras candidatas.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Celda 4: Preprocesamiento - Generaci√≥n de Lista de PALABRAS CANDIDATAS\n",
    "# ===================================================================\n",
    "def generate_candidate_lists(num_candidates, languages):\n",
    "    print(\"Descargando corpus de NLTK (puede tardar la primera vez)...\")\n",
    "    nltk.download('words', quiet=True); nltk.download('cess_esp', quiet=True)\n",
    "    print(\"Corpus descargados.\")\n",
    "    valid_chars = set('abcdefghijklmnopqrstuvwxyz')\n",
    "    word_sources = {'en': set(nltk.corpus.words.words()), 'es': set(nltk.corpus.cess_esp.words())}\n",
    "    candidate_words = {}\n",
    "    \n",
    "    for lang in languages:\n",
    "        print(f\"\\n--- Procesando diccionario de candidatos para: {lang.upper()} ---\")\n",
    "        source_words = word_sources.get(lang, set())\n",
    "        print(f\"  Corpus original cargado con {len(source_words)} palabras.\")\n",
    "        valid_words = {unidecode(w.lower()) for w in source_words if len(unidecode(w.lower())) > 2 and set(unidecode(w.lower())).issubset(valid_chars)}\n",
    "        print(f\"  Se encontraron {len(valid_words)} palabras v√°lidas despu√©s del filtro.\")\n",
    "        if len(valid_words) >= num_candidates:\n",
    "            # Seleccionar aleatoriamente para asegurar la variedad.\n",
    "            candidate_words[lang] = random.sample(sorted(list(valid_words)), num_candidates)\n",
    "            print(f\"  ‚úÖ √âxito: Se seleccionaron {len(candidate_words[lang])} palabras candidatas.\")\n",
    "        else:\n",
    "            print(f\"  ‚ùå ADVERTENCIA: No se encontraron suficientes palabras candidatas (Se necesitan {num_candidates}).\")\n",
    "            candidate_words[lang] = []\n",
    "    return candidate_words\n",
    "\n",
    "CANDIDATE_WORDS = generate_candidate_lists(NUM_CANDIDATE_WORDS, LANGUAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae4b44c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generando Dataset Visual (EMNIST) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 562M/562M [00:09<00:00, 58.4MB/s] \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da75d4d029db4e75ba97b5c1094df66e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Procesando im√°genes de EMNIST:   0%|          | 0/124800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset Visual EMNIST generado con √©xito.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Celda 5: Generaci√≥n del Dataset Visual (EMNIST)\n",
    "# ===================================================================\n",
    "def generate_visual_dataset(output_dir, raw_dir, max_examples=10):\n",
    "    print(\"\\n--- Generando Dataset Visual (EMNIST) ---\")\n",
    "    emnist_dataset = EMNIST(root=raw_dir, split='letters', download=True, train=True)\n",
    "    label_map = {i: chr(ord('a') + i - 1) for i in range(1, 27)}\n",
    "    if output_dir.exists(): shutil.rmtree(output_dir)\n",
    "    output_dir.mkdir(parents=True)\n",
    "    counts = {chr(ord('a') + i): 0 for i in range(26)}\n",
    "    for image, label_idx in tqdm(emnist_dataset, desc=\"Procesando im√°genes de EMNIST\"):\n",
    "        label_char = label_map.get(label_idx)\n",
    "        if label_char and counts[label_char] < max_examples:\n",
    "            char_dir = output_dir / label_char\n",
    "            char_dir.mkdir(exist_ok=True)\n",
    "            pil_image = image.rotate(-90, expand=True).transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            counts[label_char] += 1\n",
    "            image_path = char_dir / f\"{label_char}_{counts[label_char]}.png\"\n",
    "            pil_image.save(image_path)\n",
    "    print(\"‚úÖ Dataset Visual EMNIST generado con √©xito.\")\n",
    "\n",
    "generate_visual_dataset(output_visual_dir, raw_data_dir, max_examples=MAX_EXAMPLES_PER_GRAPHEME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c61f24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd000816a2014251bb27f1be26a37b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generando audio para 'es' en 'es':   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f259fbad248f48c2852dbf1ae3c55c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generando audio para 'es' en 'es':   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c6c185c4e8445b93412eacef58b1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generando audio para 'en' en 'en':   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff626873f0f4a4e9b333a9b343bfeb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generando audio para 'en' en 'en':   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Celda 6: Generaci√≥n de Audio para Fonemas y Palabras\n",
    "# ===================================================================\n",
    "def generate_audio(text_list, output_dir, lang):\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for text in tqdm(text_list, desc=f\"Generando audio para '{lang}' en '{output_dir.name}'\"):\n",
    "        file_path = output_dir / f\"{text}.wav\"\n",
    "        if not file_path.exists():\n",
    "            try:\n",
    "                gTTS(text, lang=lang).save(str(file_path))\n",
    "            except Exception as e:\n",
    "                print(f\"No se pudo generar audio para '{text}': {e}\")\n",
    "\n",
    "for lang in LANGUAGES:\n",
    "    generate_audio(PHONEMES[lang], output_audio_dir / lang, lang)\n",
    "    if CANDIDATE_WORDS[lang]:\n",
    "        generate_audio(CANDIDATE_WORDS[lang], output_word_audio_dir / lang, lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "395eaef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daba8c4ac38b4f079fcab03a67c11050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extrayendo embeddings de 'es':   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f7817812764a6fa3ab096fcaa116cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extrayendo embeddings de 'es':   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3714ccdf9689441da3c0237845734ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extrayendo embeddings de 'en':   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f3b9f7af24405481470524256165e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extrayendo embeddings de 'en':   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Celda 7: Extracci√≥n de Embeddings Auditivos (Wav2Vec2)\n",
    "# ===================================================================\n",
    "import librosa\n",
    "def extract_embeddings(audio_dir, embedding_dir):\n",
    "    embedding_dir.mkdir(parents=True, exist_ok=True)\n",
    "    audio_files = list(audio_dir.glob(\"*.wav\"))\n",
    "    for audio_path in tqdm(audio_files, desc=f\"Extrayendo embeddings de '{audio_dir.name}'\"):\n",
    "        text = audio_path.stem\n",
    "        embedding_path = embedding_dir / f\"{text}.npy\"\n",
    "        if not embedding_path.exists():\n",
    "            try:\n",
    "                speech_array, sr = librosa.load(str(audio_path), sr=16000)\n",
    "                inputs = processor(speech_array, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "                with torch.no_grad():\n",
    "                    outputs = model.wav2vec2(inputs.input_values.to(DEVICE))\n",
    "                    hidden_states = outputs.last_hidden_state\n",
    "                np.save(embedding_path, hidden_states.cpu().numpy().squeeze())\n",
    "            except Exception as e:\n",
    "                print(f\"No se pudo extraer embedding para '{text}': {e}\")\n",
    "\n",
    "for lang in LANGUAGES:\n",
    "    extract_embeddings(output_audio_dir / lang, output_embedding_dir / lang)\n",
    "    if CANDIDATE_WORDS[lang]:\n",
    "        extract_embeddings(output_word_audio_dir / lang, output_word_embedding_dir / lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60966f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Verificaci√≥n Final de Activos y Creaci√≥n de Diccionarios ---\n",
      "\n",
      "--- Verificando idioma: ES ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a97bb80a97344c1b72dfd3f36185649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Verificando activos (es):   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Se encontraron 200 palabras con todos sus activos generados correctamente.\n",
      "  ‚úÖ √âxito: Se gener√≥ el diccionario final 'es_words.txt' con 100 palabras verificadas.\n",
      "\n",
      "--- Verificando idioma: EN ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f90b7bb7b140a1a3afb7d394118d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Verificando activos (en):   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Se encontraron 200 palabras con todos sus activos generados correctamente.\n",
      "  ‚úÖ √âxito: Se gener√≥ el diccionario final 'en_words.txt' con 100 palabras verificadas.\n",
      "\n",
      "\n",
      "‚úÖ Todos los diccionarios finales han sido generados y verificados con √©xito.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Celda 8: Verificaci√≥n Final y Creaci√≥n de Diccionarios Definitivos\n",
    "# ===================================================================\n",
    "print(\"\\n--- Verificaci√≥n Final de Activos y Creaci√≥n de Diccionarios ---\")\n",
    "final_word_lists = {}\n",
    "can_proceed_final = True\n",
    "for lang in LANGUAGES:\n",
    "    print(f\"\\n--- Verificando idioma: {lang.upper()} ---\")\n",
    "    phoneme_dir = output_embedding_dir / lang\n",
    "    word_dir = output_word_embedding_dir / lang\n",
    "    verified_words = []\n",
    "    candidate_list = CANDIDATE_WORDS.get(lang, [])\n",
    "    if not candidate_list: continue\n",
    "    for word in tqdm(candidate_list, desc=f\"Verificando activos ({lang})\"):\n",
    "        word_embedding_exists = (word_dir / f\"{word}.npy\").exists()\n",
    "        all_phonemes_exist = all((phoneme_dir / f\"{phoneme}.npy\").exists() for phoneme in word)\n",
    "        if word_embedding_exists and all_phonemes_exist:\n",
    "            verified_words.append(word)\n",
    "    print(f\"  Se encontraron {len(verified_words)} palabras con todos sus activos generados correctamente.\")\n",
    "    if len(verified_words) >= NUM_FINAL_WORDS:\n",
    "        final_list = sorted(verified_words)[:NUM_FINAL_WORDS]\n",
    "        dict_path = dictionaries_dir / f\"{lang}_words.txt\"\n",
    "        with open(dict_path, 'w', encoding='utf-8') as f:\n",
    "            for word in final_list: f.write(f\"{word}\\n\")\n",
    "        print(f\"  ‚úÖ √âxito: Se gener√≥ el diccionario final '{dict_path.name}' con {len(final_list)} palabras verificadas.\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå ERROR CR√çTICO: No se pudieron generar suficientes activos para '{lang}'. (Se necesitan {NUM_FINAL_WORDS})\")\n",
    "        can_proceed_final = False\n",
    "if not can_proceed_final:\n",
    "    raise RuntimeError(\"No se pudieron generar todos los diccionarios finales. Revisa los logs de error.\")\n",
    "else:\n",
    "    print(\"\\n\\n‚úÖ Todos los diccionarios finales han sido generados y verificados con √©xito.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
