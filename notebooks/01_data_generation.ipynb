{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "017b8137",
   "metadata": {},
   "source": [
    "# Cuaderno 01: Generaci√≥n de Datasets y Embeddings\n",
    "\n",
    "### Objetivo üéØ\n",
    "Este cuaderno es el punto de partida fundamental de nuestro proyecto. Su objetivo es construir de manera sistem√°tica y robusta todos los **datasets paralelos** (auditivo y visual) y las **representaciones num√©ricas (embeddings)** que servir√°n de base para el entrenamiento de los modelos.\n",
    "\n",
    "### Flujo de Trabajo Consolidado ‚öôÔ∏è\n",
    "\n",
    "1.  **Configuraci√≥n e Instalaci√≥n**: Definiremos los par√°metros globales, incluyendo el **n√∫mero de palabras deseadas** para el experimento y el **modelo `wav2vec2-large`** para asegurar embeddings de dimensi√≥n 1024.\n",
    "2.  **Preprocesamiento - Generaci√≥n de Diccionarios (Robusto)**: Una nueva secci√≥n autom√°tica que:\n",
    "    - Descarga corpus de palabras para espa√±ol e ingl√©s.\n",
    "    - Filtra un gran n√∫mero de palabras candidatas que cumplen nuestros criterios (solo letras v√°lidas).\n",
    "    - **Selecciona aleatoriamente** el n√∫mero deseado de palabras para garantizar la diversidad l√©xica.\n",
    "    - Ordena alfab√©ticamente la lista final y la guarda, creando diccionarios fiables.\n",
    "3.  **Generaci√≥n del Dataset Visual (EMNIST)**: Descarga y extrae im√°genes de letras (`.png`) del dataset EMNIST, con un **l√≠mite de 10 ejemplos por grafema** para mantener el dataset balanceado.\n",
    "4.  **Generaci√≥n de Audio (gTTS)**: Crea archivos `.wav` para cada fonema y para cada palabra de nuestros nuevos y diversos diccionarios.\n",
    "5.  **Extracci√≥n de Embeddings (Wav2Vec2)**: Procesa todos los archivos `.wav` para crear su \"imagen auditiva\", asegurando que se extraiga el **`last_hidden_state`** para obtener los embeddings de dimensi√≥n 1024.\n",
    "6.  **Verificaci√≥n Final**: Se a√±ade un paso final que **verifica en el disco duro** que todos los activos necesarios para las palabras del diccionario se hayan creado con √©xito, garantizando que no habr√° errores de archivos faltantes en los cuadernos posteriores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ac34e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Celda 2: Configuraci√≥n e Instalaci√≥n\n",
    "# ===================================================================\n",
    "%pip install torch transformers gtts pandas numpy scikit-learn nltk unidecode torchvision --quiet\n",
    "\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "from torchvision.datasets import EMNIST\n",
    "from torchvision.transforms import ToPILImage\n",
    "from gtts import gTTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from unidecode import unidecode\n",
    "import shutil\n",
    "import random\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da0007ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h-lv60-self and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Wav2Vec2 cargado: 'facebook/wav2vec2-large-960h-lv60-self'\n",
      "Dimensi√≥n de embedding confirmada: 1024\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Celda 3: Par√°metros Globales\n",
    "# ===================================================================\n",
    "# --- Par√°metros del Experimento ---\n",
    "# Define con cu√°ntas palabras V√ÅLIDAS Y VERIFICADAS quieres que termine el proceso.\n",
    "NUM_FINAL_WORDS = 100\n",
    "# Buscaremos un n√∫mero mayor de candidatos para tener margen por si falla la generaci√≥n de alg√∫n archivo.\n",
    "NUM_CANDIDATE_WORDS = int(NUM_FINAL_WORDS * 2) \n",
    "MAX_EXAMPLES_PER_GRAPHEME = 10\n",
    "LANGUAGES = ['es', 'en']\n",
    "\n",
    "# Fonemas/Grafemas a generar (25 letras sin '√±' para compatibilidad)\n",
    "PHONEMES = {\n",
    "    'es': sorted(list('abcdefghijklmnopqrstuvwxyz')),\n",
    "    'en': sorted(list('abcdefghijklmnopqrstuvwxyz'))\n",
    "}\n",
    "\n",
    "# --- Rutas del Proyecto ---\n",
    "project_root = Path.cwd().parent\n",
    "raw_data_dir = project_root / \"data/01_raw\"\n",
    "dictionaries_dir = raw_data_dir / \"dictionaries\"\n",
    "output_audio_dir = project_root / \"data/02_processed/audio\"\n",
    "output_embedding_dir = project_root / \"data/02_processed/wav2vec2_embeddings\"\n",
    "output_visual_dir = project_root / \"data/02_processed/visual\"\n",
    "output_word_audio_dir = project_root / \"data/02_processed/word_audio\"\n",
    "output_word_embedding_dir = project_root / \"data/02_processed/word_embeddings\"\n",
    "\n",
    "# --- Creaci√≥n de Directorios ---\n",
    "for path in [dictionaries_dir, output_audio_dir, output_embedding_dir, output_visual_dir, output_word_audio_dir, output_word_embedding_dir]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Configuraci√≥n del Modelo de Embeddings ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Se usa el modelo 'large' para asegurar embeddings de dimensi√≥n 1024\n",
    "MODEL_ID = \"facebook/wav2vec2-large-960h-lv60-self\"\n",
    "processor = Wav2Vec2Processor.from_pretrained(MODEL_ID)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(MODEL_ID).to(DEVICE)\n",
    "EMBED_DIM = model.config.hidden_size\n",
    "print(f\"Modelo Wav2Vec2 cargado: '{MODEL_ID}'\")\n",
    "print(f\"Dimensi√≥n de embedding confirmada: {EMBED_DIM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a1816ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando corpus de NLTK (puede tardar la primera vez)...\n",
      "Corpus descargados.\n",
      "\n",
      "--- Procesando diccionario de candidatos para: ES ---\n",
      "  Corpus original cargado con 25464 palabras.\n",
      "  Se encontraron 19644 palabras v√°lidas despu√©s del filtro.\n",
      "  ‚úÖ √âxito: Se seleccionaron 200 palabras candidatas.\n",
      "\n",
      "--- Procesando diccionario de candidatos para: EN ---\n",
      "  Corpus original cargado con 235892 palabras.\n",
      "  Se encontraron 234210 palabras v√°lidas despu√©s del filtro.\n",
      "  ‚úÖ √âxito: Se seleccionaron 200 palabras candidatas.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Celda 4: Preprocesamiento - Generaci√≥n de Lista de PALABRAS CANDIDATAS\n",
    "# ===================================================================\n",
    "def generate_candidate_lists(num_candidates, languages):\n",
    "    print(\"Descargando corpus de NLTK (puede tardar la primera vez)...\")\n",
    "    nltk.download('words', quiet=True); nltk.download('cess_esp', quiet=True)\n",
    "    print(\"Corpus descargados.\")\n",
    "    valid_chars = set('abcdefghijklmnopqrstuvwxyz')\n",
    "    word_sources = {'en': set(nltk.corpus.words.words()), 'es': set(nltk.corpus.cess_esp.words())}\n",
    "    candidate_words = {}\n",
    "    \n",
    "    for lang in languages:\n",
    "        print(f\"\\n--- Procesando diccionario de candidatos para: {lang.upper()} ---\")\n",
    "        source_words = word_sources.get(lang, set())\n",
    "        print(f\"  Corpus original cargado con {len(source_words)} palabras.\")\n",
    "        valid_words = {unidecode(w.lower()) for w in source_words if len(unidecode(w.lower())) > 2 and set(unidecode(w.lower())).issubset(valid_chars)}\n",
    "        print(f\"  Se encontraron {len(valid_words)} palabras v√°lidas despu√©s del filtro.\")\n",
    "        if len(valid_words) >= num_candidates:\n",
    "            # Seleccionar aleatoriamente para asegurar la variedad.\n",
    "            candidate_words[lang] = random.sample(sorted(list(valid_words)), num_candidates)\n",
    "            print(f\"  ‚úÖ √âxito: Se seleccionaron {len(candidate_words[lang])} palabras candidatas.\")\n",
    "        else:\n",
    "            print(f\"  ‚ùå ADVERTENCIA: No se encontraron suficientes palabras candidatas (Se necesitan {num_candidates}).\")\n",
    "            candidate_words[lang] = []\n",
    "    return candidate_words\n",
    "\n",
    "CANDIDATE_WORDS = generate_candidate_lists(NUM_CANDIDATE_WORDS, LANGUAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae4b44c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generando Dataset Visual (EMNIST) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033686c4511d4257a465cd9aaa44bd6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Procesando im√°genes de EMNIST:   0%|          | 0/124800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset Visual EMNIST generado con √©xito.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Celda 5: Generaci√≥n del Dataset Visual (EMNIST)\n",
    "# ===================================================================\n",
    "def generate_visual_dataset(output_dir, raw_dir, max_examples=10):\n",
    "    print(\"\\n--- Generando Dataset Visual (EMNIST) ---\")\n",
    "    emnist_dataset = EMNIST(root=raw_dir, split='letters', download=True, train=True)\n",
    "    label_map = {i: chr(ord('a') + i - 1) for i in range(1, 27)}\n",
    "    if output_dir.exists(): shutil.rmtree(output_dir)\n",
    "    output_dir.mkdir(parents=True)\n",
    "    counts = {chr(ord('a') + i): 0 for i in range(26)}\n",
    "    for image, label_idx in tqdm(emnist_dataset, desc=\"Procesando im√°genes de EMNIST\"):\n",
    "        label_char = label_map.get(label_idx)\n",
    "        if label_char and counts[label_char] < max_examples:\n",
    "            char_dir = output_dir / label_char\n",
    "            char_dir.mkdir(exist_ok=True)\n",
    "            pil_image = image.rotate(-90, expand=True).transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            counts[label_char] += 1\n",
    "            image_path = char_dir / f\"{label_char}_{counts[label_char]}.png\"\n",
    "            pil_image.save(image_path)\n",
    "    print(\"‚úÖ Dataset Visual EMNIST generado con √©xito.\")\n",
    "\n",
    "generate_visual_dataset(output_visual_dir, raw_data_dir, max_examples=MAX_EXAMPLES_PER_GRAPHEME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c61f24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1977dc4ea754bb78deeffdbe7c29901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generando audio para 'es' en 'es':   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929b727c6a074e85964a68a7d33b0216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generando audio para 'es' en 'es':   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "589ae88efa7c4055ac4257efab25e959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generando audio para 'en' en 'en':   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537aa2e73cb74d5592b2fc738186401b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generando audio para 'en' en 'en':   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Celda 6: Generaci√≥n de Audio para Fonemas y Palabras\n",
    "# ===================================================================\n",
    "def generate_audio(text_list, output_dir, lang):\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for text in tqdm(text_list, desc=f\"Generando audio para '{lang}' en '{output_dir.name}'\"):\n",
    "        file_path = output_dir / f\"{text}.wav\"\n",
    "        if not file_path.exists():\n",
    "            try:\n",
    "                gTTS(text, lang=lang).save(str(file_path))\n",
    "            except Exception as e:\n",
    "                print(f\"No se pudo generar audio para '{text}': {e}\")\n",
    "\n",
    "for lang in LANGUAGES:\n",
    "    generate_audio(PHONEMES[lang], output_audio_dir / lang, lang)\n",
    "    if CANDIDATE_WORDS[lang]:\n",
    "        generate_audio(CANDIDATE_WORDS[lang], output_word_audio_dir / lang, lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "395eaef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b156add7b4e342eaa31024eec414569e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extrayendo embeddings de 'es':   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f7065533b2d44ae95b0d3ec13ede0d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extrayendo embeddings de 'es':   0%|          | 0/399 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b50b7383d44f299ed07cc24caee8fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extrayendo embeddings de 'en':   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db533d5815d2488e83499efedf1c2cdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extrayendo embeddings de 'en':   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Celda 7: Extracci√≥n de Embeddings Auditivos (Wav2Vec2)\n",
    "# ===================================================================\n",
    "import librosa\n",
    "def extract_embeddings(audio_dir, embedding_dir):\n",
    "    embedding_dir.mkdir(parents=True, exist_ok=True)\n",
    "    audio_files = list(audio_dir.glob(\"*.wav\"))\n",
    "    for audio_path in tqdm(audio_files, desc=f\"Extrayendo embeddings de '{audio_dir.name}'\"):\n",
    "        text = audio_path.stem\n",
    "        embedding_path = embedding_dir / f\"{text}.npy\"\n",
    "        if not embedding_path.exists():\n",
    "            try:\n",
    "                speech_array, sr = librosa.load(str(audio_path), sr=16000)\n",
    "                inputs = processor(speech_array, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "                with torch.no_grad():\n",
    "                    outputs = model.wav2vec2(inputs.input_values.to(DEVICE))\n",
    "                    hidden_states = outputs.last_hidden_state\n",
    "                np.save(embedding_path, hidden_states.cpu().numpy().squeeze())\n",
    "            except Exception as e:\n",
    "                print(f\"No se pudo extraer embedding para '{text}': {e}\")\n",
    "\n",
    "for lang in LANGUAGES:\n",
    "    extract_embeddings(output_audio_dir / lang, output_embedding_dir / lang)\n",
    "    if CANDIDATE_WORDS[lang]:\n",
    "        extract_embeddings(output_word_audio_dir / lang, output_word_embedding_dir / lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60966f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Verificaci√≥n Final de Activos y Creaci√≥n de Diccionarios ---\n",
      "\n",
      "--- Verificando idioma: ES ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec47c11c511f4496ae2f8e2d9de19e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Verificando activos (es):   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Se encontraron 200 palabras con todos sus activos generados correctamente.\n",
      "  ‚úÖ √âxito: Se gener√≥ el diccionario final 'es_words.txt' con 100 palabras verificadas.\n",
      "\n",
      "--- Verificando idioma: EN ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "394a653a47004eb8bf53d910d90f098c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Verificando activos (en):   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Se encontraron 200 palabras con todos sus activos generados correctamente.\n",
      "  ‚úÖ √âxito: Se gener√≥ el diccionario final 'en_words.txt' con 100 palabras verificadas.\n",
      "\n",
      "\n",
      "‚úÖ Todos los diccionarios finales han sido generados y verificados con √©xito.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Celda 8: Verificaci√≥n Final y Creaci√≥n de Diccionarios Definitivos\n",
    "# ===================================================================\n",
    "print(\"\\n--- Verificaci√≥n Final de Activos y Creaci√≥n de Diccionarios ---\")\n",
    "final_word_lists = {}\n",
    "can_proceed_final = True\n",
    "for lang in LANGUAGES:\n",
    "    print(f\"\\n--- Verificando idioma: {lang.upper()} ---\")\n",
    "    phoneme_dir = output_embedding_dir / lang\n",
    "    word_dir = output_word_embedding_dir / lang\n",
    "    verified_words = []\n",
    "    candidate_list = CANDIDATE_WORDS.get(lang, [])\n",
    "    if not candidate_list: continue\n",
    "    for word in tqdm(candidate_list, desc=f\"Verificando activos ({lang})\"):\n",
    "        word_embedding_exists = (word_dir / f\"{word}.npy\").exists()\n",
    "        all_phonemes_exist = all((phoneme_dir / f\"{phoneme}.npy\").exists() for phoneme in word)\n",
    "        if word_embedding_exists and all_phonemes_exist:\n",
    "            verified_words.append(word)\n",
    "    print(f\"  Se encontraron {len(verified_words)} palabras con todos sus activos generados correctamente.\")\n",
    "    if len(verified_words) >= NUM_FINAL_WORDS:\n",
    "        final_list = sorted(verified_words)[:NUM_FINAL_WORDS]\n",
    "        dict_path = dictionaries_dir / f\"{lang}_words.txt\"\n",
    "        with open(dict_path, 'w', encoding='utf-8') as f:\n",
    "            for word in final_list: f.write(f\"{word}\\n\")\n",
    "        print(f\"  ‚úÖ √âxito: Se gener√≥ el diccionario final '{dict_path.name}' con {len(final_list)} palabras verificadas.\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå ERROR CR√çTICO: No se pudieron generar suficientes activos para '{lang}'. (Se necesitan {NUM_FINAL_WORDS})\")\n",
    "        can_proceed_final = False\n",
    "if not can_proceed_final:\n",
    "    raise RuntimeError(\"No se pudieron generar todos los diccionarios finales. Revisa los logs de error.\")\n",
    "else:\n",
    "    print(\"\\n\\n‚úÖ Todos los diccionarios finales han sido generados y verificados con √©xito.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
