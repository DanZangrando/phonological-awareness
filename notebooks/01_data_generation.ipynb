{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "017b8137",
   "metadata": {},
   "source": [
    "# Cuaderno 01: Generaci√≥n de Datasets y Embeddings\n",
    "\n",
    "### Objetivo üéØ\n",
    "Este cuaderno es el punto de partida fundamental de nuestro proyecto. Su objetivo es construir de manera sistem√°tica y robusta todos los **datasets paralelos** (auditivo y visual) y las **representaciones num√©ricas (embeddings)** que servir√°n de base para el entrenamiento de los modelos.\n",
    "\n",
    "### Flujo de Trabajo Consolidado ‚öôÔ∏è\n",
    "\n",
    "1.  **Configuraci√≥n e Instalaci√≥n**: Definiremos los par√°metros globales, incluyendo el **n√∫mero de palabras deseadas** para el experimento y el **modelo `wav2vec2-large`** para asegurar embeddings de dimensi√≥n 1024.\n",
    "2.  **Preprocesamiento - Generaci√≥n de Diccionarios (Robusto)**: Una nueva secci√≥n autom√°tica que:\n",
    "    - Descarga corpus de palabras para espa√±ol e ingl√©s.\n",
    "    - Filtra un gran n√∫mero de palabras candidatas que cumplen nuestros criterios (solo letras v√°lidas).\n",
    "    - **Selecciona aleatoriamente** el n√∫mero deseado de palabras para garantizar la diversidad l√©xica.\n",
    "    - Ordena alfab√©ticamente la lista final y la guarda, creando diccionarios fiables.\n",
    "3.  **Generaci√≥n del Dataset Visual (EMNIST)**: Descarga y extrae im√°genes de letras (`.png`) del dataset EMNIST, con un **l√≠mite de 10 ejemplos por grafema** para mantener el dataset balanceado.\n",
    "4.  **Generaci√≥n de Audio (gTTS)**: Crea archivos `.wav` para cada fonema y para cada palabra de nuestros nuevos y diversos diccionarios.\n",
    "5.  **Extracci√≥n de Embeddings (Wav2Vec2)**: Procesa todos los archivos `.wav` para crear su \"imagen auditiva\", asegurando que se extraiga el **`last_hidden_state`** para obtener los embeddings de dimensi√≥n 1024.\n",
    "6.  **Verificaci√≥n Final**: Se a√±ade un paso final que **verifica en el disco duro** que todos los activos necesarios para las palabras del diccionario se hayan creado con √©xito, garantizando que no habr√° errores de archivos faltantes en los cuadernos posteriores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac34e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Celda 2: Configuraci√≥n e Instalaci√≥n\n",
    "# ===================================================================\n",
    "%pip install torch transformers gtts pandas numpy scikit-learn nltk unidecode torchvision --quiet\n",
    "\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "from torchvision.datasets import EMNIST\n",
    "from torchvision.transforms import ToPILImage\n",
    "from gtts import gTTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from unidecode import unidecode\n",
    "import shutil\n",
    "import random\n",
    "from PIL import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da0007ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h-lv60-self and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Wav2Vec2 cargado: 'facebook/wav2vec2-large-960h-lv60-self'\n",
      "Dimensi√≥n de embedding confirmada: 1024\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Celda 3: Par√°metros Globales\n",
    "# ===================================================================\n",
    "# --- Par√°metros del Experimento ---\n",
    "# Define con cu√°ntas palabras V√ÅLIDAS Y VERIFICADAS quieres que termine el proceso.\n",
    "NUM_FINAL_WORDS = 500\n",
    "# Buscaremos un n√∫mero mayor de candidatos para tener margen por si falla la generaci√≥n de alg√∫n archivo.\n",
    "NUM_CANDIDATE_WORDS = int(NUM_FINAL_WORDS * 2) \n",
    "MAX_EXAMPLES_PER_GRAPHEME = 10\n",
    "LANGUAGES = ['es', 'en']\n",
    "\n",
    "# Fonemas/Grafemas a generar (25 letras sin '√±' para compatibilidad)\n",
    "PHONEMES = {\n",
    "    'es': sorted(list('abcdefghijklmnopqrstuvwxyz')),\n",
    "    'en': sorted(list('abcdefghijklmnopqrstuvwxyz'))\n",
    "}\n",
    "\n",
    "# --- Rutas del Proyecto ---\n",
    "project_root = Path.cwd().parent\n",
    "raw_data_dir = project_root / \"data/01_raw\"\n",
    "dictionaries_dir = raw_data_dir / \"dictionaries\"\n",
    "output_audio_dir = project_root / \"data/02_processed/audio\"\n",
    "output_embedding_dir = project_root / \"data/02_processed/wav2vec2_embeddings\"\n",
    "output_visual_dir = project_root / \"data/02_processed/visual\"\n",
    "output_word_audio_dir = project_root / \"data/02_processed/word_audio\"\n",
    "output_word_embedding_dir = project_root / \"data/02_processed/word_embeddings\"\n",
    "\n",
    "# --- Creaci√≥n de Directorios ---\n",
    "for path in [dictionaries_dir, output_audio_dir, output_embedding_dir, output_visual_dir, output_word_audio_dir, output_word_embedding_dir]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Configuraci√≥n del Modelo de Embeddings ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Se usa el modelo 'large' para asegurar embeddings de dimensi√≥n 1024\n",
    "MODEL_ID = \"facebook/wav2vec2-large-960h-lv60-self\"\n",
    "processor = Wav2Vec2Processor.from_pretrained(MODEL_ID)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(MODEL_ID).to(DEVICE)\n",
    "EMBED_DIM = model.config.hidden_size\n",
    "print(f\"Modelo Wav2Vec2 cargado: '{MODEL_ID}'\")\n",
    "print(f\"Dimensi√≥n de embedding confirmada: {EMBED_DIM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a1816ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando corpus de NLTK (puede tardar la primera vez)...\n",
      "Corpus descargados.\n",
      "\n",
      "--- Procesando diccionario de candidatos para: ES ---\n",
      "  Corpus original cargado con 25464 palabras.\n",
      "  Se encontraron 19644 palabras v√°lidas despu√©s del filtro.\n",
      "  ‚úÖ √âxito: Se seleccionaron 1000 palabras candidatas.\n",
      "\n",
      "--- Procesando diccionario de candidatos para: EN ---\n",
      "  Corpus original cargado con 235892 palabras.\n",
      "  Se encontraron 234210 palabras v√°lidas despu√©s del filtro.\n",
      "  ‚úÖ √âxito: Se seleccionaron 1000 palabras candidatas.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Celda 4: Preprocesamiento - Generaci√≥n de Lista de PALABRAS CANDIDATAS\n",
    "# ===================================================================\n",
    "def generate_candidate_lists(num_candidates, languages):\n",
    "    print(\"Descargando corpus de NLTK (puede tardar la primera vez)...\")\n",
    "    nltk.download('words', quiet=True); nltk.download('cess_esp', quiet=True)\n",
    "    print(\"Corpus descargados.\")\n",
    "    valid_chars = set('abcdefghijklmnopqrstuvwxyz')\n",
    "    word_sources = {'en': set(nltk.corpus.words.words()), 'es': set(nltk.corpus.cess_esp.words())}\n",
    "    candidate_words = {}\n",
    "    \n",
    "    for lang in languages:\n",
    "        print(f\"\\n--- Procesando diccionario de candidatos para: {lang.upper()} ---\")\n",
    "        source_words = word_sources.get(lang, set())\n",
    "        print(f\"  Corpus original cargado con {len(source_words)} palabras.\")\n",
    "        valid_words = {unidecode(w.lower()) for w in source_words if len(unidecode(w.lower())) > 2 and set(unidecode(w.lower())).issubset(valid_chars)}\n",
    "        print(f\"  Se encontraron {len(valid_words)} palabras v√°lidas despu√©s del filtro.\")\n",
    "        if len(valid_words) >= num_candidates:\n",
    "            # Seleccionar aleatoriamente para asegurar la variedad.\n",
    "            candidate_words[lang] = random.sample(sorted(list(valid_words)), num_candidates)\n",
    "            print(f\"  ‚úÖ √âxito: Se seleccionaron {len(candidate_words[lang])} palabras candidatas.\")\n",
    "        else:\n",
    "            print(f\"  ‚ùå ADVERTENCIA: No se encontraron suficientes palabras candidatas (Se necesitan {num_candidates}).\")\n",
    "            candidate_words[lang] = []\n",
    "    return candidate_words\n",
    "\n",
    "CANDIDATE_WORDS = generate_candidate_lists(NUM_CANDIDATE_WORDS, LANGUAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae4b44c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generando Dataset Visual (EMNIST) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17c5733d7c364059addf617e612e7d7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Procesando im√°genes de EMNIST:   0%|          | 0/124800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset Visual EMNIST generado con √©xito.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Celda 5: Generaci√≥n del Dataset Visual (EMNIST)\n",
    "# ===================================================================\n",
    "def generate_visual_dataset(output_dir, raw_dir, max_examples=10):\n",
    "    print(\"\\n--- Generando Dataset Visual (EMNIST) ---\")\n",
    "    emnist_dataset = EMNIST(root=raw_dir, split='letters', download=True, train=True)\n",
    "    label_map = {i: chr(ord('a') + i - 1) for i in range(1, 27)}\n",
    "    if output_dir.exists(): shutil.rmtree(output_dir)\n",
    "    output_dir.mkdir(parents=True)\n",
    "    counts = {chr(ord('a') + i): 0 for i in range(26)}\n",
    "    for image, label_idx in tqdm(emnist_dataset, desc=\"Procesando im√°genes de EMNIST\"):\n",
    "        label_char = label_map.get(label_idx)\n",
    "        if label_char and counts[label_char] < max_examples:\n",
    "            char_dir = output_dir / label_char\n",
    "            char_dir.mkdir(exist_ok=True)\n",
    "            pil_image = image.rotate(-90, expand=True).transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            counts[label_char] += 1\n",
    "            image_path = char_dir / f\"{label_char}_{counts[label_char]}.png\"\n",
    "            pil_image.save(image_path)\n",
    "    print(\"‚úÖ Dataset Visual EMNIST generado con √©xito.\")\n",
    "\n",
    "generate_visual_dataset(output_visual_dir, raw_data_dir, max_examples=MAX_EXAMPLES_PER_GRAPHEME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c61f24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3d09ac4fcb74693bcd486803c87c27c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generando audio para 'es' en 'es':   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ddb35e27db242b48fda8c9480276a90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generando audio para 'es' en 'es':   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se pudo generar audio para 'estipuladas': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'coloca': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'descendido': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'comprender': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'cuidado': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'cabritos': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'cielos': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'mostoles': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'dialogo': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'intensiva': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n",
      "No se pudo generar audio para 'cdu': 429 (Too Many Requests) from TTS API. Probable cause: Unknown\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m generate_audio(PHONEMES[lang], output_audio_dir / lang, lang)\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m CANDIDATE_WORDS[lang]:\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[43mgenerate_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCANDIDATE_WORDS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_word_audio_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mgenerate_audio\u001b[39m\u001b[34m(text_list, output_dir, lang)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_path.exists():\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m         \u001b[43mgTTS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     12\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo se pudo generar audio para \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages/gtts/tts.py:335\u001b[39m, in \u001b[36mgTTS.save\u001b[39m\u001b[34m(self, savefile)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Do the TTS API request and write result to file.\u001b[39;00m\n\u001b[32m    326\u001b[39m \n\u001b[32m    327\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    332\u001b[39m \n\u001b[32m    333\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mstr\u001b[39m(savefile), \u001b[33m\"\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwrite_to_fp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    336\u001b[39m     f.flush()\n\u001b[32m    337\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mSaved to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, savefile)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages/gtts/tts.py:316\u001b[39m, in \u001b[36mgTTS.write_to_fp\u001b[39m\u001b[34m(self, fp)\u001b[39m\n\u001b[32m    304\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Do the TTS API request(s) and write bytes to a file-like object.\u001b[39;00m\n\u001b[32m    305\u001b[39m \n\u001b[32m    306\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    312\u001b[39m \n\u001b[32m    313\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpart-\u001b[39;49m\u001b[38;5;132;43;01m%i\u001b[39;49;00m\u001b[33;43m written to \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages/gtts/tts.py:268\u001b[39m, in \u001b[36mgTTS.stream\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    266\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m requests.Session() \u001b[38;5;28;01mas\u001b[39;00m s:\n\u001b[32m    267\u001b[39m         \u001b[38;5;66;03m# Send request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m         r = \u001b[43ms\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m            \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43murllib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetproxies\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    275\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mheaders-\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, idx, r.request.headers)\n\u001b[32m    276\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33murl-\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, idx, r.request.url)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages/requests/adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    641\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages/urllib3/connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    562\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    568\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:1428\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1426\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1427\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1428\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1430\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/socket.py:707\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    709\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/ssl.py:1252\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1249\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1250\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1251\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1252\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1254\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/ssl.py:1104\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1104\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1105\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1106\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Celda 6: Generaci√≥n de Audio para Fonemas y Palabras\n",
    "# ===================================================================\n",
    "def generate_audio(text_list, output_dir, lang):\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for text in tqdm(text_list, desc=f\"Generando audio para '{lang}' en '{output_dir.name}'\"):\n",
    "        file_path = output_dir / f\"{text}.wav\"\n",
    "        if not file_path.exists():\n",
    "            try:\n",
    "                gTTS(text, lang=lang).save(str(file_path))\n",
    "            except Exception as e:\n",
    "                print(f\"No se pudo generar audio para '{text}': {e}\")\n",
    "\n",
    "for lang in LANGUAGES:\n",
    "    generate_audio(PHONEMES[lang], output_audio_dir / lang, lang)\n",
    "    if CANDIDATE_WORDS[lang]:\n",
    "        generate_audio(CANDIDATE_WORDS[lang], output_word_audio_dir / lang, lang)\n",
    "        time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395eaef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943a47d967ff43419bdab1b19f0961dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extrayendo embeddings de 'es':   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1855f7f4b0403dad587603fb240efe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extrayendo embeddings de 'es':   0%|          | 0/788 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5df8d06cb974e0a82eaadc5952e6e83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extrayendo embeddings de 'en':   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f4c7374d6f4345b6f3d202a5b6f094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extrayendo embeddings de 'en':   0%|          | 0/799 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Celda 7: Extracci√≥n de Embeddings Auditivos (Wav2Vec2)\n",
    "# ===================================================================\n",
    "import librosa\n",
    "def extract_embeddings(audio_dir, embedding_dir):\n",
    "    embedding_dir.mkdir(parents=True, exist_ok=True)\n",
    "    audio_files = list(audio_dir.glob(\"*.wav\"))\n",
    "    for audio_path in tqdm(audio_files, desc=f\"Extrayendo embeddings de '{audio_dir.name}'\"):\n",
    "        text = audio_path.stem\n",
    "        embedding_path = embedding_dir / f\"{text}.npy\"\n",
    "        if not embedding_path.exists():\n",
    "            try:\n",
    "                speech_array, sr = librosa.load(str(audio_path), sr=16000)\n",
    "                inputs = processor(speech_array, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "                with torch.no_grad():\n",
    "                    outputs = model.wav2vec2(inputs.input_values.to(DEVICE))\n",
    "                    hidden_states = outputs.last_hidden_state\n",
    "                np.save(embedding_path, hidden_states.cpu().numpy().squeeze())\n",
    "            except Exception as e:\n",
    "                print(f\"No se pudo extraer embedding para '{text}': {e}\")\n",
    "\n",
    "for lang in LANGUAGES:\n",
    "    extract_embeddings(output_audio_dir / lang, output_embedding_dir / lang)\n",
    "    if CANDIDATE_WORDS[lang]:\n",
    "        extract_embeddings(output_word_audio_dir / lang, output_word_embedding_dir / lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60966f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Verificaci√≥n Final de Activos y Creaci√≥n de Diccionarios ---\n",
      "\n",
      "--- Verificando idioma: ES ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47df0b5da73d420fa62f95382b6c7f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Verificando activos (es):   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Se encontraron 400 palabras con todos sus activos generados correctamente.\n",
      "  ‚úÖ √âxito: Se gener√≥ el diccionario final 'es_words.txt' con 200 palabras verificadas.\n",
      "\n",
      "--- Verificando idioma: EN ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f98d2a00fe482da22dcc3361747388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Verificando activos (en):   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Se encontraron 400 palabras con todos sus activos generados correctamente.\n",
      "  ‚úÖ √âxito: Se gener√≥ el diccionario final 'en_words.txt' con 200 palabras verificadas.\n",
      "\n",
      "\n",
      "‚úÖ Todos los diccionarios finales han sido generados y verificados con √©xito.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Celda 8: Verificaci√≥n Final y Creaci√≥n de Diccionarios Definitivos\n",
    "# ===================================================================\n",
    "print(\"\\n--- Verificaci√≥n Final de Activos y Creaci√≥n de Diccionarios ---\")\n",
    "final_word_lists = {}\n",
    "can_proceed_final = True\n",
    "for lang in LANGUAGES:\n",
    "    print(f\"\\n--- Verificando idioma: {lang.upper()} ---\")\n",
    "    phoneme_dir = output_embedding_dir / lang\n",
    "    word_dir = output_word_embedding_dir / lang\n",
    "    verified_words = []\n",
    "    candidate_list = CANDIDATE_WORDS.get(lang, [])\n",
    "    if not candidate_list: continue\n",
    "    for word in tqdm(candidate_list, desc=f\"Verificando activos ({lang})\"):\n",
    "        word_embedding_exists = (word_dir / f\"{word}.npy\").exists()\n",
    "        all_phonemes_exist = all((phoneme_dir / f\"{phoneme}.npy\").exists() for phoneme in word)\n",
    "        if word_embedding_exists and all_phonemes_exist:\n",
    "            verified_words.append(word)\n",
    "    print(f\"  Se encontraron {len(verified_words)} palabras con todos sus activos generados correctamente.\")\n",
    "    if len(verified_words) >= NUM_FINAL_WORDS:\n",
    "        final_list = sorted(verified_words)[:NUM_FINAL_WORDS]\n",
    "        dict_path = dictionaries_dir / f\"{lang}_words.txt\"\n",
    "        with open(dict_path, 'w', encoding='utf-8') as f:\n",
    "            for word in final_list: f.write(f\"{word}\\n\")\n",
    "        print(f\"  ‚úÖ √âxito: Se gener√≥ el diccionario final '{dict_path.name}' con {len(final_list)} palabras verificadas.\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå ERROR CR√çTICO: No se pudieron generar suficientes activos para '{lang}'. (Se necesitan {NUM_FINAL_WORDS})\")\n",
    "        can_proceed_final = False\n",
    "if not can_proceed_final:\n",
    "    raise RuntimeError(\"No se pudieron generar todos los diccionarios finales. Revisa los logs de error.\")\n",
    "else:\n",
    "    print(\"\\n\\n‚úÖ Todos los diccionarios finales han sido generados y verificados con √©xito.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
