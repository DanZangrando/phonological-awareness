{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "017b8137",
   "metadata": {},
   "source": [
    "# Cuaderno 01: Generación de Datasets Auditivos y Visuales\n",
    "\n",
    "**Objetivo:** Crear los datasets paralelos que servirán de base para todo el proyecto:\n",
    "1.  **Dataset Auditivo**: Generar archivos de audio `.wav` para una lista de fonemas/letras clave.\n",
    "2.  **Dataset Visual**: Descargar y extraer imágenes de letras (`.png`) del dataset **EMNIST** que correspondan a los grafemas de nuestras listas.\n",
    "\n",
    "**Flujo de Trabajo:**\n",
    "1.  **Instalación de Librerías**: Instalar `gTTS`, `pydub` y `torchvision`.\n",
    "2.  **Configuración**: Definir las listas de fonemas/grafemas y las rutas de salida para ambos datasets.\n",
    "3.  **Parte A**: Generar los archivos de audio.\n",
    "4.  **Parte B**: Descargar, filtrar y guardar las imágenes de letras correspondientes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35353702",
   "metadata": {},
   "source": [
    "## Paso 1: Instalación de Librerías\n",
    "\n",
    "Instalamos las librerías necesarias:\n",
    "* `gTTS` y `pydub`: Para la síntesis de voz y manejo de audio.\n",
    "* `torch` y `torchvision`: Para descargar y manipular el dataset de imágenes EMNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da5ba352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gTTS in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (2.5.4)\n",
      "Requirement already satisfied: pydub in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (0.25.1)\n",
      "Requirement already satisfied: torch in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (2.8.0)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.23.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: matplotlib in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (3.10.5)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from gTTS) (2.32.5)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from gTTS) (8.1.8)\n",
      "Requirement already satisfied: filelock in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: numpy in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from matplotlib) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from requests<3,>=2.27->gTTS) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from requests<3,>=2.27->gTTS) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from requests<3,>=2.27->gTTS) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from requests<3,>=2.27->gTTS) (2025.8.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/daniel/Proyectos/phonological-awareness/venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Using cached torchvision-0.23.0-cp312-cp312-manylinux_2_28_x86_64.whl (8.6 MB)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gTTS pydub torch torchvision matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd86ca3",
   "metadata": {},
   "source": [
    "## Paso 2: Configuración General\n",
    "\n",
    "Importamos librerías y definimos las listas de fonemas/grafemas y las rutas de salida. Ahora incluimos rutas para los datos visuales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a1816ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se guardará un máximo de 50 imágenes por grafema.\n",
      "Fonemas a procesar para español: 27\n",
      "Fonemas a procesar para inglés: 33\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import EMNIST\n",
    "from PIL import Image\n",
    "\n",
    "# --- Rutas de Salida ---\n",
    "project_root = Path.cwd().parent\n",
    "\n",
    "# Rutas para el dataset auditivo\n",
    "output_dir_audio_es = project_root / \"data/02_processed/phoneme_audio/es\"\n",
    "output_dir_audio_en = project_root / \"data/02_processed/phoneme_audio/en\"\n",
    "output_dir_audio_es.mkdir(parents=True, exist_ok=True)\n",
    "output_dir_audio_en.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Rutas para el dataset visual\n",
    "output_dir_emnist_root = project_root / \"data/01_raw/emnist\"\n",
    "output_dir_visual_es = project_root / \"data/02_processed/grapheme_images/es\"\n",
    "output_dir_visual_en = project_root / \"data/02_processed/grapheme_images/en\"\n",
    "output_dir_visual_es.mkdir(parents=True, exist_ok=True)\n",
    "output_dir_visual_en.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Listas de Fonemas/Grafemas ---\n",
    "phonemes_es = [\n",
    "    'a', 'e', 'i', 'o', 'u', 'b', \"c\", 'd', 'f', 'g', 'j',\"h\", 'k', 'l', 'm', 'n', 'ñ', 'p', 'r', 'rr', 's', 't', 'y',\"v\", 'z', 'ch', 'll'\n",
    "]\n",
    "phonemes_en = [\n",
    "    'a', 'e', 'i', 'o', 'u', 'ay', 'ee', 'igh', 'oh', 'oo', 'b',\"c\", 'd', 'f', 'g', 'h', 'j', 'k', 'l', 'm', 'n', 'p', 'r', 's', 't', 'v', 'w', 'y', 'z', 'ch', 'sh', 'th', 'ng'\n",
    "]\n",
    "\n",
    "# --- Parámetros de Procesamiento ---\n",
    "MAX_IMAGES_PER_LETTER = 50\n",
    "\n",
    "print(f\"Se guardará un máximo de {MAX_IMAGES_PER_LETTER} imágenes por grafema.\")\n",
    "print(f\"Fonemas a procesar para español: {len(phonemes_es)}\")\n",
    "print(f\"Fonemas a procesar para inglés: {len(phonemes_en)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628a5678",
   "metadata": {},
   "source": [
    "## Parte A: Generación del Dataset Auditivo\n",
    "\n",
    "Esta sección genera los archivos `.wav` para cada fonema/letra de nuestras listas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6980ddb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iniciando generación de audio para: ES ---\n",
      "(1/27) Audio para 'a' guardado.\n",
      "(2/27) Audio para 'e' guardado.\n",
      "(3/27) Audio para 'i' guardado.\n",
      "(4/27) Audio para 'o' guardado.\n",
      "(5/27) Audio para 'u' guardado.\n",
      "(6/27) Audio para 'b' guardado.\n",
      "(7/27) Audio para 'c' guardado.\n",
      "(8/27) Audio para 'd' guardado.\n",
      "(9/27) Audio para 'f' guardado.\n",
      "(10/27) Audio para 'g' guardado.\n",
      "(11/27) Audio para 'j' guardado.\n",
      "(12/27) Audio para 'h' guardado.\n",
      "(13/27) Audio para 'k' guardado.\n",
      "(14/27) Audio para 'l' guardado.\n",
      "(15/27) Audio para 'm' guardado.\n",
      "(16/27) Audio para 'n' guardado.\n",
      "(17/27) Audio para 'ñ' guardado.\n",
      "(18/27) Audio para 'p' guardado.\n",
      "(19/27) Audio para 'r' guardado.\n",
      "(20/27) Audio para 'rr' guardado.\n",
      "(21/27) Audio para 's' guardado.\n",
      "(22/27) Audio para 't' guardado.\n",
      "(23/27) Audio para 'y' guardado.\n",
      "(24/27) Audio para 'v' guardado.\n",
      "(25/27) Audio para 'z' guardado.\n",
      "(26/27) Audio para 'ch' guardado.\n",
      "(27/27) Audio para 'll' guardado.\n",
      "\n",
      "--- Iniciando generación de audio para: EN ---\n",
      "(1/33) Audio para 'a' guardado.\n",
      "(2/33) Audio para 'e' guardado.\n",
      "(3/33) Audio para 'i' guardado.\n",
      "(4/33) Audio para 'o' guardado.\n",
      "(5/33) Audio para 'u' guardado.\n",
      "(6/33) Audio para 'ay' guardado.\n",
      "(7/33) Audio para 'ee' guardado.\n",
      "(8/33) Audio para 'igh' guardado.\n",
      "(9/33) Audio para 'oh' guardado.\n",
      "(10/33) Audio para 'oo' guardado.\n",
      "(11/33) Audio para 'b' guardado.\n",
      "(12/33) Audio para 'c' guardado.\n",
      "(13/33) Audio para 'd' guardado.\n",
      "(14/33) Audio para 'f' guardado.\n",
      "(15/33) Audio para 'g' guardado.\n",
      "(16/33) Audio para 'h' guardado.\n",
      "(17/33) Audio para 'j' guardado.\n",
      "(18/33) Audio para 'k' guardado.\n",
      "(19/33) Audio para 'l' guardado.\n",
      "(20/33) Audio para 'm' guardado.\n",
      "(21/33) Audio para 'n' guardado.\n",
      "(22/33) Audio para 'p' guardado.\n",
      "(23/33) Audio para 'r' guardado.\n",
      "(24/33) Audio para 's' guardado.\n",
      "(25/33) Audio para 't' guardado.\n",
      "(26/33) Audio para 'v' guardado.\n",
      "(27/33) Audio para 'w' guardado.\n",
      "(28/33) Audio para 'y' guardado.\n",
      "(29/33) Audio para 'z' guardado.\n",
      "(30/33) Audio para 'ch' guardado.\n",
      "(31/33) Audio para 'sh' guardado.\n",
      "(32/33) Audio para 'th' guardado.\n",
      "(33/33) Audio para 'ng' guardado.\n",
      "\n",
      "--- Proceso de generación de audio completado. ---\n"
     ]
    }
   ],
   "source": [
    "def generate_audio_files(phoneme_list, lang_code, output_path):\n",
    "    print(f\"\\n--- Iniciando generación de audio para: {lang_code.upper()} ---\")\n",
    "    for i, phoneme in enumerate(phoneme_list):\n",
    "        wav_filepath = output_path / f\"{phoneme}.wav\"\n",
    "        if wav_filepath.exists():\n",
    "            print(f\"({i+1}/{len(phoneme_list)}) Audio para '{phoneme}' ya existe. Omitiendo.\")\n",
    "            continue\n",
    "        try:\n",
    "            tts = gTTS(text=phoneme, lang=lang_code, slow=True)\n",
    "            mp3_temp_path = output_path / \"temp.mp3\"\n",
    "            tts.save(mp3_temp_path)\n",
    "            audio = AudioSegment.from_mp3(mp3_temp_path)\n",
    "            audio.export(wav_filepath, format=\"wav\", parameters=[\"-ac\", \"1\", \"-ar\", \"16000\"])\n",
    "            os.remove(mp3_temp_path)\n",
    "            print(f\"({i+1}/{len(phoneme_list)}) Audio para '{phoneme}' guardado.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando '{phoneme}': {e}\")\n",
    "            if os.path.exists(mp3_temp_path): os.remove(mp3_temp_path)\n",
    "\n",
    "# Generar audios para ambos idiomas\n",
    "generate_audio_files(phonemes_es, 'es', output_dir_audio_es)\n",
    "generate_audio_files(phonemes_en, 'en', output_dir_audio_en)\n",
    "print(\"\\n--- Proceso de generación de audio completado. ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d893173",
   "metadata": {},
   "source": [
    "## Parte B: Generación del Dataset Visual\n",
    "\n",
    "Ahora, descargamos el dataset EMNIST y extraemos las imágenes de las letras que corresponden a nuestros grafemas de una sola letra (ej. 'a', 'b', 'c'). Las imágenes se guardarán en subcarpetas por cada letra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06d93d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Descargando y preparando EMNIST ---\n",
      "\n",
      "--- Extrayendo un máximo de 50 imágenes para 24 grafemas ---\n",
      "(1/24) Se guardaron 50 imágenes para 'a'.\n",
      "(2/24) Se guardaron 50 imágenes para 'e'.\n",
      "(3/24) Se guardaron 50 imágenes para 'i'.\n",
      "(4/24) Se guardaron 50 imágenes para 'o'.\n",
      "(5/24) Se guardaron 50 imágenes para 'u'.\n",
      "(6/24) Se guardaron 50 imágenes para 'b'.\n",
      "(7/24) Se guardaron 50 imágenes para 'c'.\n",
      "(8/24) Se guardaron 50 imágenes para 'd'.\n",
      "(9/24) Se guardaron 50 imágenes para 'f'.\n",
      "(10/24) Se guardaron 50 imágenes para 'g'.\n",
      "(11/24) Se guardaron 50 imágenes para 'j'.\n",
      "(12/24) Se guardaron 50 imágenes para 'h'.\n",
      "(13/24) Se guardaron 50 imágenes para 'k'.\n",
      "(14/24) Se guardaron 50 imágenes para 'l'.\n",
      "(15/24) Se guardaron 50 imágenes para 'm'.\n",
      "(16/24) Se guardaron 50 imágenes para 'n'.\n",
      "Grafema 'ñ' no encontrado en EMNIST 'letters'.\n",
      "(18/24) Se guardaron 50 imágenes para 'p'.\n",
      "(19/24) Se guardaron 50 imágenes para 'r'.\n",
      "(20/24) Se guardaron 50 imágenes para 's'.\n",
      "(21/24) Se guardaron 50 imágenes para 't'.\n",
      "(22/24) Se guardaron 50 imágenes para 'y'.\n",
      "(23/24) Se guardaron 50 imágenes para 'v'.\n",
      "(24/24) Se guardaron 50 imágenes para 'z'.\n",
      "\n",
      "--- Extrayendo un máximo de 50 imágenes para 24 grafemas ---\n",
      "(1/24) Se guardaron 50 imágenes para 'a'.\n",
      "(2/24) Se guardaron 50 imágenes para 'e'.\n",
      "(3/24) Se guardaron 50 imágenes para 'i'.\n",
      "(4/24) Se guardaron 50 imágenes para 'o'.\n",
      "(5/24) Se guardaron 50 imágenes para 'u'.\n",
      "(6/24) Se guardaron 50 imágenes para 'b'.\n",
      "(7/24) Se guardaron 50 imágenes para 'c'.\n",
      "(8/24) Se guardaron 50 imágenes para 'd'.\n",
      "(9/24) Se guardaron 50 imágenes para 'f'.\n",
      "(10/24) Se guardaron 50 imágenes para 'g'.\n",
      "(11/24) Se guardaron 50 imágenes para 'h'.\n",
      "(12/24) Se guardaron 50 imágenes para 'j'.\n",
      "(13/24) Se guardaron 50 imágenes para 'k'.\n",
      "(14/24) Se guardaron 50 imágenes para 'l'.\n",
      "(15/24) Se guardaron 50 imágenes para 'm'.\n",
      "(16/24) Se guardaron 50 imágenes para 'n'.\n",
      "(17/24) Se guardaron 50 imágenes para 'p'.\n",
      "(18/24) Se guardaron 50 imágenes para 'r'.\n",
      "(19/24) Se guardaron 50 imágenes para 's'.\n",
      "(20/24) Se guardaron 50 imágenes para 't'.\n",
      "(21/24) Se guardaron 50 imágenes para 'v'.\n",
      "(22/24) Se guardaron 50 imágenes para 'w'.\n",
      "(23/24) Se guardaron 50 imágenes para 'y'.\n",
      "(24/24) Se guardaron 50 imágenes para 'z'.\n",
      "\n",
      "--- Proceso de generación de imágenes completado. ---\n"
     ]
    }
   ],
   "source": [
    "def generate_visual_dataset(phoneme_list, emnist_dataset, output_path, max_images):\n",
    "    \"\"\"\n",
    "    Filtra EMNIST y guarda un número máximo de imágenes por grafema.\n",
    "    \"\"\"\n",
    "    class_to_char = {i: c for i, c in enumerate(emnist_dataset.classes) if c.isalpha()}\n",
    "    char_to_class = {c: i for i, c in class_to_char.items()}\n",
    "    \n",
    "    single_char_graphemes = [p for p in phoneme_list if len(p) == 1 and p.isalpha()]\n",
    "    \n",
    "    print(f\"\\n--- Extrayendo un máximo de {max_images} imágenes para {len(single_char_graphemes)} grafemas ---\")\n",
    "    \n",
    "    images_by_label = {label: [] for label in range(len(emnist_dataset.classes))}\n",
    "    for image, label in emnist_dataset:\n",
    "        images_by_label[label].append(image)\n",
    "\n",
    "    for i, grapheme in enumerate(single_char_graphemes):\n",
    "        grapheme_lower = grapheme.lower()\n",
    "        if grapheme_lower in char_to_class:\n",
    "            class_idx = char_to_class[grapheme_lower]\n",
    "            grapheme_dir = output_path / grapheme_lower\n",
    "            grapheme_dir.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            num_existing = len(list(grapheme_dir.glob(\"*.png\")))\n",
    "            if num_existing >= max_images:\n",
    "                print(f\"({i+1}/{len(single_char_graphemes)}) Límite de imágenes para '{grapheme_lower}' ya alcanzado. Omitiendo.\")\n",
    "                continue\n",
    "\n",
    "            images_saved_count = 0\n",
    "            for img_obj in images_by_label[class_idx]:\n",
    "                if images_saved_count >= max_images:\n",
    "                    break\n",
    "                \n",
    "                img = img_obj.transpose(Image.Transpose.ROTATE_270)\n",
    "                img = img.transpose(Image.Transpose.FLIP_LEFT_RIGHT)\n",
    "                # Usamos el contador actual para el nombre del archivo\n",
    "                img.save(grapheme_dir / f\"{grapheme_lower}_{num_existing + images_saved_count}.png\")\n",
    "                images_saved_count += 1\n",
    "            \n",
    "            print(f\"({i+1}/{len(single_char_graphemes)}) Se guardaron {images_saved_count} imágenes para '{grapheme_lower}'.\")\n",
    "        else:\n",
    "            print(f\"Grafema '{grapheme_lower}' no encontrado en EMNIST 'letters'.\")\n",
    "\n",
    "# --- Descargar el dataset EMNIST una sola vez ---\n",
    "print(\"\\n--- Descargando y preparando EMNIST ---\")\n",
    "emnist_data = EMNIST(root=output_dir_emnist_root, split='letters', download=True)\n",
    "            \n",
    "# --- CORRECCIÓN: Llamadas a la función actualizadas ---\n",
    "# Añadimos el argumento 'max_images' que ahora es requerido\n",
    "generate_visual_dataset(phonemes_es, emnist_data, output_dir_visual_es, max_images=MAX_IMAGES_PER_LETTER)\n",
    "generate_visual_dataset(phonemes_en, emnist_data, output_dir_visual_en, max_images=MAX_IMAGES_PER_LETTER)\n",
    "\n",
    "print(\"\\n--- Proceso de generación de imágenes completado. ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
